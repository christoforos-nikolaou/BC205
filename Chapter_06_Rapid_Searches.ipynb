{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c72a629dba5ae9edebcad565c17c3988d814021371aabb3db62cb04d2b10dbfe",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BC205: Algorithms for Bioinformatics.\n",
    "## VI. Rapid Searches\n",
    "\n",
    "### Christoforos Nikolaou\n",
    "\n",
    "### Dealing with the problem of sequence similarity and comparison, we have up to now seen how:\n",
    "* We can quantify the similarity between two sequences using scoring schemes that are either arbitrarily defined, or based on **substitution matrices** obtained from molecular evolution approaches.\n",
    "* We can define an objective methodology that maximizes sequence similarity through the concept of **alignment**.\n",
    "* We can distinguish between **global** (for the entire sequence length) and **local** (for subparts of the sequences) alignment.\n",
    "\n",
    "### We are now moving on into a different aspect of the problem of sequence similarity that stems from the scale of sequence size and volume\n",
    "\n",
    "a. Creating of a PWM from a given sequnce"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "import regex as re\n",
    "f=open(\"files/gata.fa\", 'r')\n",
    "seqs = []\n",
    "for line in f:\n",
    "    x=re.match(\">\", line)\n",
    "    if x == None:\n",
    "        seqs.append(line.rstrip())\n",
    "#\n",
    "def pwm(sequences):\n",
    "    nuc = ['A', 'C', 'G', 'T']\n",
    "    profile=[[0 for i in range(len(sequences[0]))] for j in range(len(nuc))]\n",
    "    #\n",
    "    for instance in sequences:\n",
    "        for j in range(len(instance)):\n",
    "            residue=instance[j]\n",
    "            profile[nuc.index(residue)][j]+=1\n",
    "            profile[nuc.index(residue)][j]=float(profile[nuc.index(residue)][j])\n",
    "    import numpy as np\n",
    "    pwm = np.array(profile)\n",
    "    pwm = pwm/len(sequences)\n",
    "    return(pwm)\n",
    "\n",
    "mypwm=pwm(seqs)\n",
    "    \n"
   ]
  },
  {
   "source": [
    "KMP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfasta(fastafile):\n",
    "    import regex as re\n",
    "    f=open(fastafile, 'r')\n",
    "    seq = \"\"\n",
    "    total = 0\n",
    "    for line in f:\n",
    "        x=re.match(\">\", line)\n",
    "        if x == None:\n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "    seq=seq.replace('N','')\n",
    "    f.close()\n",
    "    return(seq)\n",
    "\n",
    "targetsequence=readfasta(\"files/ecoli.fa\")\n"
   ]
  },
  {
   "source": [
    "BM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nuccomp(sequence):\n",
    "    import numpy as np\n",
    "    nucfreq = [0, 0, 0, 0]\n",
    "    nuc = ['A', 'C', 'G', 'T']\n",
    "    for i in range(len(nuc)):\n",
    "        nucfreq[i]=sequence.count(nuc[i])\n",
    "    nucfreq=np.array(nucfreq)/len(sequence)\n",
    "    return(nucfreq)\n",
    "\n",
    "nucfreqs=nuccomp(targetsequence)"
   ]
  },
  {
   "source": [
    "FASTA\n",
    "\n",
    "FastA - Steps\n",
    "Hashing: FastA locates regions of the query sequence and matching regions in the database sequences that have high densities of exact word matches. (without gaps) The length of the matched word is called the ktup parameter.\n",
    "Scoring: The ten highest scoring regions are rescored using a scoring matrix. The score for such a pair of regions is saved as the init1 score.\n",
    "Introduction of Gaps: FastA determines if any of the initial regions from different diagonals may be joined together to form an approximate alignment with gaps. Only non-overlapping regions may be joined. The score for the joined regions is the sum of the scores of the initial regions minus a joining penalty for each gap. The score of the highest scoring region, at the end of this step, is saved as the initn score.\n",
    "Alignment: After computing the initial scores, FastA determines the best segment of similarity between the query sequence and the search set sequence, using a variation of the Smith-Waterman algorithm. The score for this alignment is the opt score.\n",
    "Random Sequence Simulation: In order to evaluate the significance of such alignment FastA empirically estimates the score distribution from the alignment of many random pairs of sequences. More precisely, the characters of the query sequences are reshuffled (to maintain bias due to length and character composition) and searched against a random subset of the database. This empirical distribution is extrapolated, assuming it is an extreme value distribution, and each alignment to the real query is assigned a Z-score and an E-score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a PSSM\n",
    "def pssm(pwm, nucfreqs):\n",
    "    import numpy as np\n",
    "    import math\n",
    "    pseudocount=0.01\n",
    "    pssm=[[0 for i in range(len(pwm[0]))] for j in range(len(nucfreqs))]\n",
    "    for i in range(len(nucfreqs)):\n",
    "        pssm[i]=(np.array(pwm[i])+pseudocount)/nucfreqs[i]\n",
    "    for i in range(len(pssm)):\n",
    "        for k in range(len(pssm[0])):\n",
    "            pssm[i][k]=math.log(pssm[i][k])/math.log(2)\n",
    "    return(pssm)\n",
    "\n",
    "mypssm=pssm(mypwm, nucfreqs)"
   ]
  },
  {
   "source": [
    "c. Searching a sequence with a PWM/PSSM or with Hamming Distance "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pssmSearch(pssm, sequence, threshold):\n",
    "    nuc = ['A', 'C', 'G', 'T']\n",
    "    hits = []\n",
    "    instances = []\n",
    "    for i in range(len(sequence)-len(pssm[0])):\n",
    "        instance=sequence[i:i+len(pssm[0])]\n",
    "        score=0\n",
    "        for l in range(len(instance)):\n",
    "            score=score+pssm[nuc.index(instance[l])][l]\n",
    "        if (score > threshold):\n",
    "            hits.append(i)\n",
    "            instances.append(instance) \n",
    "    return(hits, instances)\n",
    "\n",
    "out=pssmSearch(mypssm, targetsequence, 9)"
   ]
  },
  {
   "source": [
    "BLAST"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to be added"
   ]
  },
  {
   "source": [
    "### The next problem. Discover a new motif from a given set of sequences\n",
    "\n",
    "#### Part 1. Formulating the problem\n",
    "1. Given a set of sequences that each contains an instance of the motif, find the motif.\n",
    "\n",
    "#### A first approach \n",
    "\n",
    "Assuming we have a way to \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "source": [
    "1. Given a set of s sequences: Find a set of k-mers (for a given\n",
    "length k, one from each sequence) that maximizes the score (or\n",
    "minimizes the distance) of each (one) k-mer with its sequence\n",
    "2. Collect k-mers\n",
    "3. Create a motif from them\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "source": [
    "### Brute Force Approach\n",
    "\n",
    "What is the complexity of the BFA?\n",
    "1. Number of k-mers 4k\n",
    "2. Number of k-mers in each sequence: (n − k + 1)\n",
    "3. Number of calculations for each k-mer given s sequences of\n",
    "length n: (n − k + 1)s\n",
    "4. Total number of calculations 4k (n − k + 1)s\n",
    "\n",
    "The complexity of the algorithm is at least O(ns ).\n",
    "\n",
    "We need something faster!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "source": [
    "* Assuming we have a way to calculate the distance of a k-mer k\n",
    "\n",
    "```\n",
    "from a given sequence seq  \n",
    "    for k in kmers:  \n",
    "        for seq in sequences:  \n",
    "            if distance(k, seq)<min_distance:  \n",
    "                min_distance<-distance(k,seq)  \n",
    "                motif[seq]<-k\n",
    "```\n",
    "\n",
    "* Because each k-mer needs to pass only once through each\n",
    "sequence, the median string has O(4k ) complexity because k is\n",
    "(usually) much shorter than the length of the sequence.\n",
    "\n",
    "* However, it is still quite slow and for k>10 its implementation\n",
    "is still unapplicable.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "source": [
    "### An alternative\n",
    "\n",
    "* Assume a greedy approach to go through all sequences\n",
    "updating a motif every time\n",
    "\n",
    "* Starting from sequence i:\n",
    "\n",
    "1. find the most common k-mer\n",
    "2. create a profile from it (adding pseudocounts to all 0-values)\n",
    "3. go to the next sequence\n",
    "4. choose the k-mer that best fits the profile\n",
    "5. store that k-mer in the collection and update profile\n",
    "6. iterate steps 3->5.\n",
    "\n",
    "* We’ ve just described a Greedy approach for discovering a\n",
    "motif p of a given length k among t sequences.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "source": [
    "### A greedy Approach\n",
    "\n",
    "* Assuming a set of s sequences and a given consensus k-mer k:\n",
    "\n",
    "* We will construct a PWM “on the go” as we move from one\n",
    "sequence to the next.\n",
    "1. For i=1 :\n",
    "2. For each k in seq_i:  \n",
    "    2.1 For i = 2 to i = s:  \n",
    "    2.2 Find the best (smallest distance) kmer in seq_i  \n",
    "    2.3 Build a profile  \n",
    "    2.4 If the score(profile) is better than all previous update profile  \n",
    "3. Repeat\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Analysis. Greedy Approach\n",
    "\n",
    "1. Why Greedy: It takes kmers from the first sequence only to\n",
    "scan in the following. Thus it doesn’t go through all\n",
    "combinations of sequences and k-mers. As we’ve seen above\n",
    "the trade-off is speed.\n",
    "2. KEY: It assumes that all sequences contain the motif. If the\n",
    "first sequence doesn’t contain the motif (in any variation) then\n",
    "we are doomed in looking for something that is non-sensical.\n",
    "3. A way to go around this is to sample a small percentage of\n",
    "sequences randomly, which brings us to the next-to-last chapter\n",
    "of the motif finding problem\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### A randomized approach\n",
    "\n",
    "* In the Greedy Approach we take the kmers from the first\n",
    "sequence and scan over the rest. In this way an initial wrong\n",
    "choice may lead you to disastrous results.\n",
    "* In a Randomized Approach we start, instead with a\n",
    "collection of s k-mers, one from each sequence, build a profile,\n",
    "scan the sequences with that profile, update it and repeat until\n",
    "the k-mer set is good enough match for the updated profile.\n",
    "* Stop and think of the problems we get rid of with this\n",
    "approach.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Pseudocode\n",
    "\n",
    "```\n",
    "for seq in sequences:  \n",
    "    profile[seq]<-random(k, seq)  \n",
    "    while distance(profile, sequences)>threshold  \n",
    "        for seq in sequences:  \n",
    "        profile[seq]<-max(k, profile, seq)  \n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  }
 ]
}