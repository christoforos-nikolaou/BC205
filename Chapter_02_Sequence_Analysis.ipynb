{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC205: Algorithms for Bioinformatics.\n",
    "## II. Biological Sequence Analysis\n",
    "### Christoforos Nikolaou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Biological Sequence Analysis\n",
    "* Biological Sequence Analysis includes all lexicographic, statistical, or modeling types of analyses conducted on biological sequences such as DNA, RNA and proteins. In this class we will start looking into real biological problems, focusing on DNA sequences. \n",
    "* We will discuss some very basic concepts of computation such as hashing.\n",
    "* We will then turn to the implementation of the things we learnt last time using Brute Force and Divide and Conquer Approaches.\n",
    "* We will go back the concept of Binary Search and implement it the context of Genome Analysis.\n",
    "\n",
    "#### The biological problems:  \n",
    "* Compare different species on the basis of DNA composition\n",
    "* Find evidence of horizontal gene transfer in a bacterial genome\n",
    "* Locate the Origin of Repication of a Bacterial Genome\n",
    "\n",
    "#### Bioinformatics Warm-Up\n",
    "1. You are given a DNA sequence\n",
    "    * Can you count the number of nucleotides of each of the four bases (A, G, C, T)?\n",
    "    * How many calculations will you need?\n",
    "    * How will you implement it?\n",
    "2. Now consider the same problem only instead of nucleotides we need to count the number of all octanucleotides. What do you need to consider to attack the problem? What is different between the 4 mononucleotides and the 8^4 octanucleotides?\n",
    "\n",
    "#### Aspects of DNA Composition\n",
    "* GC content\n",
    "* k-mer frequencies\n",
    "* genomic signatures\n",
    "* parity distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GC content\n",
    "We call GC content (or GC%) the ratio of (G+C) nucleotides of a given DNA sequence\n",
    "* Why is it important? G-C pairs are linked with 3 hydrogen bonds, while A-T ones with 2. High GC genomes are more stable in terms of physical chemistry.\n",
    "\n",
    "![GC Content](figures/GCcontent.jpeg)\n",
    "\n",
    "\n",
    "#### GC is related to:\n",
    "* Biochemical level: Thermal stability\n",
    "* Evolutionary level: Organism Phylogeny, Mutational pressures\n",
    "* Genomic level: Genome size\n",
    "* Functional level: Functional role of underlying sequences\n",
    "* and many more\n",
    "\n",
    "#### GC content in Genomic Sequences\n",
    "* Bacteria: GC% is highly variable **between** species\n",
    "* Bacteria: GC% is rather homogeneous **within** each genome\n",
    "* Bacteria: GC% can be used in their classification\n",
    "\n",
    "![GC Content](figures/GCcontentTree.jpeg)\n",
    "\n",
    "#### GC content in Genomic Sequences\n",
    "* Eukaryotes: Very homogeneous overall GC% (~40-45% in all animals)\n",
    "* Eukaryotes: Fluctuation of GC contentalong the chromosomes and organization in areas of (rather) stable GC%\n",
    "* Eukaryotes: Regions of stable high/low GC content that segregate mammalian genomes in isochores\n",
    "\n",
    "\n",
    "#### Problem 1: GC content in Bacterial Genomes\n",
    "* Given the DNA sequence of a Bacterial Genome, calculate its GC content:\n",
    "    * Read the Sequence\n",
    "    * Enumerate G\n",
    "    * Enumerate C\n",
    "    * Divide (G+C) over length of the sequence\n",
    "\n",
    "#### GCContent. Pseudocode\n",
    "* Î¤he idea is to **exhaustively** enumerate all mononucleotides, therefore our approach is a very basic Brute Force approach.\n",
    "* Given that the content of the sequence is unknown we have no other choice.\n",
    "* We will proceed by reading each nucleotide in the sequence and check its value. Then increment a variable each time we find a G or a C.\n",
    "\n",
    "#### GCContent: Implementation (naive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive GC content\n",
    "\n",
    "def naiveGC(genomefile):\n",
    "    file = open(genomefile, 'r')\n",
    "\n",
    "    seq = \"\"\n",
    "    window = 1000\n",
    "    total = 0\n",
    "    nG = nC = 0\n",
    "    GCCont = 0\n",
    "    times = 0\n",
    "    count = 0\n",
    "    for line in file:\n",
    "        count += 1\n",
    "        if (count > 1): # the first line contains the non-sequence header so we discard it \n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "\n",
    "    for k in range(len(seq)):\n",
    "        if(seq[k]==\"G\"):\n",
    "            nG+=1\n",
    "        elif(seq[k]==\"C\"):\n",
    "            nC+=1\n",
    "    GCContent=(nG+nC)/len(seq)\n",
    "    return(GCContent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EcoliGC = naiveGC('files/ecoli.fa')\n",
    "StaurGC = naiveGC('files/Staaur.fa')\n",
    "print(EcoliGC, StaurGC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCContent: Implementation (using Python's count function)\n",
    "\n",
    "The above approach is extremely naive as it makes use not so much of an exhaustive search (this needs to be done anyway in order to enumerate all instances), but because of the naiva approach to test each nucleotide against the pattern. \n",
    "We ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastGC(genomefile):\n",
    "\n",
    "    import regex as re\n",
    "\n",
    "    file = open(genomefile, 'r')\n",
    "\n",
    "    seq = \"\"\n",
    "    total = 0\n",
    "    nG = nC = 0\n",
    "    GCCont = 0\n",
    "    times = 0\n",
    "    count = 0\n",
    "    for line in file:\n",
    "        count += 1\n",
    "        if (count > 1):\n",
    "            length = len(line)\n",
    "            total = total+length\n",
    "            seq = seq+line[0:length-1]\n",
    "    file.close()\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    nC = seq.count(\"C\")\n",
    "    nG = seq.count(\"G\")\n",
    "    GCContent = (nG+nC)/len(seq);\n",
    "    return(GCContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EcoliGC = fastGC('files/ecoli.fa')\n",
    "StaurGC = fastGC('files/Staaur.fa')\n",
    "print(EcoliGC, StaurGC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have basically done is use a built-in python function to search and count for all instances of the two nucleotides.\n",
    "We will come back to this later on. We now have a method to calculate the GC% of a given genome and can move on to some practical analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sequence composition to infer phylogeny\n",
    "In bacteria sequence composition is stable throughout the genome but varies widely between species. One can use simple measures of the nucleotide constitution to infer phylogenetic relationships between species. Below, we will try to do just that, first just by using the GC%.\n",
    "\n",
    "#### Hands on #1:\n",
    "* Download a couple of bacterial genome sequences from ENSEMBL Bacteria (http://bacteria.ensembl.org/index.html)\n",
    "* Implement GC content\n",
    "* Report the results\n",
    "\n",
    "* An example would be\n",
    "\n",
    "Genome | GC |\n",
    "------------ | -------------\n",
    "a-Bac1 | 0.334\n",
    "e-Bac2 | 0.595\n",
    "e-Bac3 | 0.668\n",
    "g-Bac4 | 0.409\n",
    "e-Bac5 | 0.551\n",
    "a-Bac6 | 0.352\n",
    "a-Bac7 | 0.354\n",
    "g-Bac8 | 0.418\n",
    "g-Bac9 | 0.434\n",
    "e-Bac8 | 0.627\n",
    "\n",
    "\n",
    "#### Problem 2: Variability of GC content _between_ Bacterial Genomes\n",
    "* Given a number of bacterial genomes:  \n",
    "    - Get their genome sequences  \n",
    "    - Calculate the GC contents  \n",
    "    - Calculate differences between the GC contents  \n",
    "    - Rank genomes based on their differences  \n",
    "* Pseudocode:\n",
    "    * Perform GC_content on each of the genomes you downloaded  \n",
    "    * Calculate D_(i,j)=|GC_i-GC_j| over all i,j  \n",
    "    * Sort D_(i,j)\n",
    "\n",
    "#### Problem 2: Approach\n",
    "* Below we will do this on a set of precalculated GC% values from 10 different bacterial genomes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('files/GCContent.tsv', 'r')\n",
    "\n",
    "i=0\n",
    "GCC={}\n",
    "for line in f:\n",
    "    i=i+1\n",
    "    if(i>1):\n",
    "        species=line.split()[0]\n",
    "        GC=line.split()[1]\n",
    "        GCC[species]=float(GC)\n",
    "\n",
    "gcdistances={}\n",
    "for genome1 in GCC.keys():\n",
    "    for genome2 in GCC.keys():\n",
    "        pair=genome1+\":\"+genome2\n",
    "        gcdistances[pair]=abs(float(GCC[genome1])-float(GCC[genome2]))\n",
    "        gcdistances[pair]=round(gcdistances[pair],2)\n",
    "\n",
    "sorted(gcdistances.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look how we can use this simple quantity to infer relationships between different genomes. \n",
    "In the following, we make use of some python functions to organize the genomes in a tree structure that resembles the way evolutionary biologists try to infer phylogenetic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clustering of a dataset \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Load the dataframe and assign values/labels\n",
    "df = pd.read_csv('files/GCContent_simple.csv')\n",
    "dvalues = df['GCContent'].values.reshape(-1,1)\n",
    "dlabels = list(df['Genome'])\n",
    "\n",
    "# Calculate the distances\n",
    "distances = pdist(dvalues)\n",
    "\n",
    "# Convert the pairwise distances into a square distance matrix\n",
    "distance_matrix = squareform(distances)\n",
    "\n",
    "# Calculate the linkage matrix using Ward's method\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "sns.set_style('white')\n",
    "dendrogram(linkage_matrix, labels=dlabels, color_threshold=0, orientation='left')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how smaller values are obtained for same bacterial family (a-, g- and e-proteobacteria) which results in them being grouped together in the same clade of the dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3: What about different regions of the genome?\n",
    "* We just saw how genomic GC% values may be used to draw conclusions for bacterial phylogeny\n",
    "* But: How representative is the GC% value you calculated above?\n",
    "* And: How efficiently can it be used to describe a genome?\n",
    "\n",
    "#### Problem 3: Why should we care?\n",
    "* We mentioned that GC% is stable within bacterial genomes\n",
    "* **But** Some areas of bacterial genomes are special\n",
    "* Parts of the bacterial genome have been \"horizontally\" (as opposed to vertically, i.e. from their \"mom\") transferred from other species.\n",
    "\n",
    "![Horizontal gene transfer (HGT)](figures/HGT.png)\n",
    "\n",
    "#### Problem 3: Stability of GC content _along_ Bacterial Genomes\n",
    "* Regions of \"strange\", or \"deviating\" GC% values in a given genome are red flags of HGT. The problem now is:\n",
    "    * Given a bacterial genome sequence:  \n",
    "    * Locate regions of the genome where horizontal gene transfer may have occurred.\n",
    "\n",
    "#### Problem 3: Approach\n",
    "* Choose a window to scan your sequence. This will be your resolution.\n",
    "* Calculate GC per window\n",
    "* Try to locate GC values that deviate from the genome average\n",
    "\n",
    "#### Problem 3: The core\n",
    "* We basically repeat the approach for GC content but now we calculate one value for each window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def windowGC(genomefile, window):\n",
    "\n",
    "    import regex as re\n",
    "    f=open(genomefile, 'r')\n",
    "\n",
    "    seq = \"\"\n",
    "    nG = nC = 0\n",
    "    total = 0\n",
    "    window = int(window)\n",
    "\n",
    "    for line in f:\n",
    "        x=re.match(\">\", line)\n",
    "        if x == None:\n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "    f.close()\n",
    "    seq = seq.upper()\n",
    "\n",
    "    step=int(window/10)-1 # we use a 10% sliding overlap between windows\n",
    "    times=int(len(seq)/step);\n",
    "\n",
    "    GCwin = {}\n",
    "    for i in range(times-10): \n",
    "        DNA=seq[i*step:i*step+window]\n",
    "        nC=DNA.count(\"C\")\n",
    "        nG=DNA.count(\"G\")\n",
    "        GCwin[i*step] = (nG+nC)/window\n",
    "    \n",
    "    return(GCwin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EcoliWGC = windowGC(\"files/ecoli.fa\", 10000)\n",
    "print(list(EcoliWGC.values())[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see how we can visualize this in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EcoliWGC = windowGC(\"files/ecoli.fa\", 10000)\n",
    "# Create a figure and axis\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the line\n",
    "plt.plot(EcoliWGC.keys(), EcoliWGC.values(), label='E.coli', color='blue', linewidth=2)  \n",
    "\n",
    "# Add labels and title\n",
    "plt.title('GC content along the genome')\n",
    "plt.xlabel('genome coordinates')\n",
    "plt.ylabel('GC%')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hands-on #2:\n",
    "* Get the genome sequence of St. aureus\n",
    "* Implement Sliding GC\n",
    "* Locate positions in the genome with extreme values of GC\n",
    "* The problem is: **What do we mean by \"extreme values\"?** How do we define \"extreme\"?\n",
    "\n",
    "#### Problem 3: Statistics Interlude\n",
    "* Given a set/sample of values, how can we decide on whether a value could be part of that sample or not?\n",
    "* In our problem: We know that the GC% of bacteria tends to be characteristic of the genome. Can we \"spot\" regions of the genome that bear GC% values that are _different_ from that characteristic value?\n",
    "* Q1: How will we define that characteristic value?\n",
    "* Q2: How will we quantify the _difference_ as big enough or not?\n",
    "\n",
    "#### Problem 3: Theoretical basis (simplified)\n",
    "* Central Limit Theorem (simplified):     \n",
    "    * Regardless of the underlying distribution, the mean of a large number of samples follow the normal distribution.  \n",
    "    * We can thus model GC values per window based on the normal distribution\n",
    "\n",
    "#### Problem 3: The statistics\n",
    "* We will model the \"characteristic value\" as the mean of GC values for all windows\n",
    "* We will also calculate the standard deviation of these values to assess the variance\n",
    "* We will then apply a technique called Z-transformation\n",
    "\n",
    "#### Z-transformation\n",
    "* Given a value x, we can compare x to a normal distribution with mean=m and standard deviation=std with the z-score:\n",
    "    Z(x)= (x - m)/std  \n",
    "    Z(x) is thus the difference of x from m in units of standard deviation.  \n",
    "    Knowing that in a normal distribution ~99.5% of the values fall within +/-3*std a value of Z(x)>3 or Z(x)<-3 makes it highly unlikely that x is part of our distribution.\n",
    "\n",
    "![Normal Distribution](figures/NormalDistribution.jpeg)\n",
    "\n",
    "#### Problem 3. Predicting HGT locations\n",
    "* We can now combine sliding GC content calculations with a Z-score transformation and a filtering for |Z|>=3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_GC(genomefile, window, threshold):\n",
    "    \n",
    "    import regex as re\n",
    "    import numpy as np\n",
    "    f=open(genomefile, 'r')\n",
    "\n",
    "    seq = \"\"\n",
    "    nG = nC = 0\n",
    "    total = 0\n",
    "    window = int(window)\n",
    "\n",
    "    for line in f:\n",
    "        x=re.match(\">\", line)\n",
    "        if x == None:\n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "    f.close()\n",
    "\n",
    "    step=int(window/10) # we use a 10% sliding overlap between windows\n",
    "    times=int(len(seq)/step);\n",
    "\n",
    "    GCwin = {}\n",
    "    for i in range(times): \n",
    "        DNA=seq[i*step:i*step+window]\n",
    "        nC=DNA.count(\"C\")\n",
    "        nG=DNA.count(\"G\")\n",
    "        GCwin[i*step] = (nG+nC)/window\n",
    "    \n",
    "    GCcont =  list(GCwin.values())\n",
    "    mGC=np.mean(GCcont)\n",
    "    sdGC=np.std(GCcont)\n",
    "    zGC=(GCcont-mGC)/sdGC\n",
    "    for i in range(len(zGC)):\n",
    "        if abs(zGC[i]) >= threshold:\n",
    "            print(i*step, zGC[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_GC('files/Staaur.fa', 10000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_GC(genomefile, window, threshold):\n",
    "    import numpy as np\n",
    "    GCwin = windowGC(genomefile, window)\n",
    "    GCcont =  list(GCwin.values())\n",
    "    mGC=np.mean(GCcont)\n",
    "    sdGC=np.std(GCcont)\n",
    "    zGC=(GCcont-mGC)/sdGC\n",
    "    #for i in range(len(zGC)):\n",
    "    #    if abs(zGC[i]) >= threshold:\n",
    "    #        print(i*(window/10), zGC[i])\n",
    "    return(zGC)\n",
    "\n",
    "Z_GC(\"files/ecoli.fa\", 1000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EcoliÎGC = list(Z_GC(\"files/ecoli.fa\", 10000, 3))\n",
    "print(EcoliÎGC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EcoliÎGC = list(Z_GC(\"files/ecoli.fa\", 10000, 3))\n",
    "# Create a figure and axis\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the line\n",
    "plt.plot(EcoliWGC.keys(), EcoliÎGC, label='E.coli', color='blue', linewidth=2)  \n",
    "\n",
    "plt.axhline(y=-3, color='red', linestyle='--', label='Lower Boundary')\n",
    "plt.axhline(y=3, color='red', linestyle='--', label='Upper Boundary')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Z-GC content along the genome')\n",
    "plt.xlabel('genome coordinates')\n",
    "plt.ylabel('z-GC%')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Question\n",
    "\n",
    "In the above output we see a lot of reported values coming from consecutive indices (i.e. coordinates that are adjacent to each other). \n",
    "Complete the function Z_GC() so that it reports ranges, that is genomic intervals that are supported by the **mean Z-score** of the range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2: Revisited\n",
    "\n",
    "* Background DNA composition has some **functional** role besides simply reflecting mutational pressures\n",
    "* This means that in some cases we need to know why the local composition is guided by _other_ aspects of molecular evolution. e.g. why would rRNA genes be G+C-rich even in AT-rich genomes?\n",
    "* We need to find a way to control for _background nucleotide composition_\n",
    "\n",
    "#### Problem 2 Revisited: Distinguishing between genomes through their sequence composition\n",
    "1. Going beyond the GC content\n",
    "2. Going beyond simple bases (mononucleotides, k=1)\n",
    "3. Analyzing all dinucleotide frequencies of k=2\n",
    "\n",
    "* Pseudocode:\n",
    "    * For each kmer in _4^k_ k-mers\n",
    "    * Calculate N(kmer)\n",
    "    * Create a table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem: How to count k-mer frequencies\n",
    "* For mononucleotides we did it with a Brute Force approach. However the mononucleotides are 4. The k-mers are 4^k.\n",
    "* How can we count the frequencies of k-mers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allkmers(genomefile, k):\n",
    "    # genomefile is a fasta file with one sequence\n",
    "    # k is the length of kmers you want to calculate\n",
    "    # example call: kmers(\"myfasta.fa\", 5) for all existing 5-mers in myfasta.fa\n",
    "    import regex as re\n",
    "    import itertools\n",
    "\n",
    "    # Importing sequence\n",
    "    file = open(genomefile, 'r')\n",
    "    seq = \"\"\n",
    "    count = 0\n",
    "    for line in file:\n",
    "        count +=1\n",
    "        if (count > 1) :\n",
    "            length=len(line)\n",
    "            seq=seq+line[0:length-1]\n",
    "            \n",
    "    file.close()\n",
    "\n",
    "    seq = re.sub(\"[^AGCT]\", \"\", seq)\n",
    "\n",
    "    # Creating the kmer combination table\n",
    "    nucleotides = ['A', 'C', 'G', 'T']\n",
    "    mykmers = [''.join(p) for p in itertools.product(nucleotides, repeat=k)]\n",
    "\n",
    "    # Counting kmer occurrence in the sequence\n",
    "    kmertable = {} \n",
    "    for i in mykmers:\n",
    "        kmertable[i]=len([m.start() for m in re.finditer(rf'(?={str(i)})', seq)])\n",
    "\n",
    "    kmertable = {k: float(v) / len(seq) for k, v in kmertable.items()}\n",
    "    return(kmertable)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "allkmers('files/ecoli.fa', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to do this for k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "allkmers('files/ecoli.fa', 5)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Stop and think:\n",
    "  1. Do we need **all** k-mers?\n",
    "  2. Do we need to check each k-mer at every step?\n",
    "* How many calculations do we need if we answer \"yes\" to 1,2 above.\n",
    "\n",
    "\n",
    "#### Solution: Hashing Strategy instead of Brute Force pattern comparisons\n",
    "* Read the sequence in chunks of _k_ nucleotides\n",
    "* For each subsequence increment a dictionary value with the subsequence as key\n",
    "\n",
    "#### Problem 2 Revisited: K-mer frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashkmers(genomefile, k):\n",
    "    # genomefile is a fasta file with one sequence\n",
    "    # k is the length of kmers you want to calculate\n",
    "    # example call: kmers(\"myfasta.fa\", 5) for all existing 5-mers in myfasta.fa\n",
    "    import regex as re\n",
    "\n",
    "    file = open(genomefile, 'r')\n",
    "\n",
    "    seq = \"\"\n",
    "    kmertable = {} \n",
    "\n",
    "    count = 0\n",
    "    for line in file:\n",
    "        count +=1\n",
    "        if (count > 1) :\n",
    "            length=len(line)\n",
    "            seq=seq+line[0:length-1]\n",
    "            \n",
    "    file.close()\n",
    "\n",
    "    seq = re.sub(\"[^AGCT]\", \"\", seq)\n",
    "\n",
    "    for i in range(len(seq)-k):\n",
    "        DNA=seq[i:i+k]\n",
    "        if DNA not in kmertable.keys():\n",
    "            kmertable[DNA]=1\n",
    "        else:\n",
    "            kmertable[DNA]+=1\n",
    "\n",
    "    kmertable = {k: float(v) / len(seq) for k, v in kmertable.items()}\n",
    "    kmertable = sorted(kmertable.items()) #sorting by key (alphabetically)\n",
    "    return(kmertable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashkmers('files/ecoli.fa', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the hashing strategy with the allkmers strategy in the case of 5-mers (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "hashkmers('files/ecoli.fa', 5)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Taking the complexity into account is imperative in the case of combinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 Revisited: A table of _4^k_ frequencies of occurrence  \n",
    "Base | A | T | G | C\n",
    "------------- | ------------- | ------------- | ------------- | -------------\n",
    "A | 0.090 | 0.112 | 0.048 | 0.053\n",
    "T | 0.095 | 0.090 | 0.064 | 0.053\n",
    "G | 0.052 | 0.052 | 0.023 | 0.034\n",
    "C | 0.066 | 0.048 | 0.026 | 0.023\n",
    "\n",
    "* Values may be seen as \"probabilities\" of finding each k-mer in the sequence\n",
    "* Can we use the notion of the probability to modify the table so that we get rid of the background nucleotide composition?\n",
    "\n",
    "#### Problem 2 Revisited: Removing Background Composition\n",
    "* The problem stated above persists at the level of k-mers: The background DNA composition may affect our results\n",
    "* At the k-mer level we can remove the background using ratios of observed/expected frequencies\n",
    "* Which is the expected frequency of a given k-mer?\n",
    "\n",
    "#### Problem 2 Revisited: Observed/Expected(o/e) k-mer frequencies\n",
    "* Mathematics Interlude:\n",
    "    * Assume two events A, B that are linked with each other\n",
    "    * We then say that A and B are dependent (or conditioned) and we have a \"conditional probability\" of A happening given B is also happening\n",
    "    * We can think of k-mers the same way: a k-mer is more probable to occur if its constituent mono-mers are occurring\n",
    "    * Bottomline: Any given k-mer's frequency of occurrence is dependent on the frequencies of occurrence of its mononucleotides. Thus:\n",
    "\n",
    "Given a k-mer of length k the o/e-ratio frequency is defined as:  \n",
    "  $$R[N_1N_2..N_k]=F[N_1N_2..N_k]/(F[N_1]F[N_2]..F[N_k])$$\n",
    "\n",
    "In this way we can define a new table of modified frequencies that is independent of mono-nucleotide composition\n",
    "\n",
    "#### Problem 2 Revisited: Observed/Expected K-mer frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rkmers(genomefile, k):\n",
    "    import regex as re\n",
    "\n",
    "    file = open(genomefile, 'r')\n",
    "\n",
    "    seq = \"\"\n",
    "    kmertable = {} \n",
    "\n",
    "    count = 0\n",
    "    for line in file:\n",
    "        count +=1\n",
    "        if (count > 1) :\n",
    "            length=len(line)\n",
    "            seq=seq+line[0:length-1]\n",
    "            \n",
    "    file.close()\n",
    "\n",
    "    seq = re.sub(\"[^AGCT]\", \"\", seq)\n",
    "    \n",
    "    # calculation of background nucleotide probability\n",
    "    pnuc = {}\n",
    "    pnuc['A'] = float(seq.count('A')/len(seq))\n",
    "    pnuc['C'] = float(seq.count('C')/len(seq))\n",
    "    pnuc['G'] = float(seq.count('G')/len(seq))\n",
    "    pnuc['T'] = float(seq.count('T')/len(seq))\n",
    "    GCcont=pnuc['G']+pnuc['C']\n",
    "    \n",
    "    for i in range(len(seq)-k):\n",
    "        DNA=seq[i:i+k]\n",
    "        if DNA not in kmertable.keys():\n",
    "            kmertable[DNA]=1\n",
    "        else:\n",
    "            kmertable[DNA]+=1\n",
    "\n",
    "    kmertable = {k: float(v) / len(seq) for k, v in kmertable.items()}\n",
    "    \n",
    "    rkmertable = kmertable\n",
    "    for kmer in kmertable.keys():\n",
    "        pkmer=1\n",
    "        for j in range(len(kmer)):\n",
    "            nuc = list(kmer)[j]\n",
    "            pkmer = pkmer * pnuc[nuc]\n",
    "        rkmertable[kmer]=round(kmertable[kmer]/(pkmer),3)\n",
    "    \n",
    "    return(rkmertable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkmers('files/ecoli.fa', 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 Revisited: A table of o/e 4^k frequencies of occurrence  \n",
    "Base | A | G | C | T\n",
    "------------- | ------------- | ------------- | ------------- | -------------\n",
    "A | 0.800 | 0.997 | 0.878 | 0.949\n",
    "G | 0.848 | 0.799 | 1.174 | 0.957\n",
    "C | 0.946 | 0.955 | 0.848 | 1.252\n",
    "T | 1.183 | 0.872 | 0.946 | 0.841\n",
    "\n",
    "* Notice how values now go >1. What does this mean?\n",
    "* How is this table better (or not) than the previous one?\n",
    "\n",
    "#### Genomic Signatures: Comparing o/e k-mer composition\n",
    "* Genomic Signatures are defined as the table of o/e k-mers for a given genome\n",
    "* We can use these tables to analyze distances between genomes. (Hint: even eukaryote genomes!)\n",
    "\n",
    "#### Hands-on #3:\n",
    "* Get chromosome 1 from (human, mouse, fly, worm, yeast)\n",
    "* Use a genomic signature approach to cluster genomic signatures from different genomes\n",
    "* Calculate the distance between rho_xy(p) and rho_xy(s) to create a table of distances.\n",
    "\n",
    "#### Problem 4: Finding the DNA Replication in a bacterial genome\n",
    "* Bacterial Genomes replicated their genome starting at one point and proceeding towards the opposite point in  the circular genome from both directions.\n",
    "* Bacterial genomes also have a particular distribution of nucleotides along their genome\n",
    "* The difference of A-T (and G-C) complementary nucleotides goes through a sort of \"phase transition\" that splits the genome approximately in half.\n",
    "* Do you know what this split is?\n",
    "* Do you know why it is so?\n",
    "\n",
    "#### How is this related to Sequence Analysis?\n",
    "* Due to the pioneering work of E. Chargaff we know that A~T and G~C in **single-stranded DNA**\n",
    "* We know that this holds for all complete genomes except very few exceptions\n",
    "* The exceptions are the few genomes that **do not** replicate symmetrically\n",
    "* DNA-strand parity:\n",
    "    * Strand X is replicated in-continuously\n",
    "    * Accumulates more substitutions\n",
    "    * If substitutions are biased the strand will guide the change in both strands through base-pairing\n",
    "\n",
    "![Genome of Staphylococcus aureus](figures/Figure00_02.jpg)\n",
    "\n",
    "#### Approaching the problem\n",
    "* We thus expect (and observe) the parity to be violated and that this violation occurs symmetrically on either side of the OriC\n",
    "* We are looking for a way to locate this _transition_ in the parity violation\n",
    "* We thus need:\n",
    "    * A measure of the parity\n",
    "    * A way to monitor this measure along the genome\n",
    "    * A way to locate abrupt changes in its values\n",
    "\n",
    "#### Breaking the problem into pieces\n",
    "1. Analyze the DNA composition _along_ the genome\n",
    "2. Calculate a quantity that will be informative\n",
    "3. Create a condition that will test the location of the Ori\n",
    "\n",
    "* Pseudocode: Given a bacterial genome:\n",
    "    * Count nucleotides in windows of N base pairs\n",
    "    * Calculate the scaled AT-skew as (A-T)/(A+T)\n",
    "    * Create an array of the skew values along the genome\n",
    "    * Locate the transition point\n",
    "\n",
    "#### Problem 4: Parity Measure Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "f=open('files/Staaur.fa', 'r')\n",
    "\n",
    "import regex as re\n",
    "\n",
    "seq = \"\"\n",
    "\n",
    "for line in f:\n",
    "    x=re.match(\">\", line)\n",
    "    if x == None:\n",
    "        length=len(line)\n",
    "        seq=seq+line[0:length-1]\n",
    "f.close()\n",
    "\n",
    "window=1000\n",
    "step=100\n",
    "times=int(len(seq)/step)\n",
    "\n",
    "ATparity = []\n",
    "for i in range(times):\n",
    "    DNA=seq[i*step:i*step+window]\n",
    "    A=DNA.count(\"A\")\n",
    "    T=DNA.count(\"T\")\n",
    "    C=DNA.count(\"C\")\n",
    "    G=DNA.count(\"G\")\n",
    "    ATparity.append(float(A-T)/float(A+T))\n",
    "\n",
    "for k in range(10):\n",
    "    print(k,\":\",ATparity[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an alternative of the above for reading the fasta file with Pythons SeqIO function from the BIO library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "with open(output_file) as out_file:\n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, fasta.seq.tostring()\n",
    "        new_sequence = some_function(sequence)\n",
    "        write_fasta(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4: Plotting the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import regex as re  \n",
    "\n",
    "f = open('files/Staaur.fa', 'r')\n",
    "seq = \"\"\n",
    "total = 0\n",
    "A=T=G=C=[]\n",
    "times=0;\n",
    "for line in f:\n",
    "\tx=re.match(\">\", line)\n",
    "\tif x == None:\n",
    "\t\tlength=len(line)\n",
    "\t\ttotal=total+length\n",
    "\t\tseq=seq+line[0:length-1]\n",
    "f.close()\n",
    "\n",
    "x=[]\n",
    "ATparity=[]\n",
    "window=100000\n",
    "step=10000\n",
    "times=int(len(seq)/step);\n",
    "for i in range(times):\n",
    "    x.append(i*step)\n",
    "    DNA=seq[i*step:i*step+window]\n",
    "    A=DNA.count(\"A\")\n",
    "    T=DNA.count(\"T\")\n",
    "    C=DNA.count(\"C\")\n",
    "    G=DNA.count(\"G\")\n",
    "    ATparity.append(float(A-T)/float(A+T))\n",
    "\n",
    "# plotting points as a scatter plot\n",
    "plt.plot(x, ATparity, color= \"green\", linewidth = 3.0)\n",
    "plt.axhline(y = 0, color = 'grey', linewidth = 2.0)\n",
    "\n",
    "# plotting vertical lines at Ori and Ter\n",
    "plt.axvline(x = 1080000, color = 'red')\n",
    "plt.axvline(x = 2450000, color = 'blue')\n",
    "\n",
    "#plt.scatter(x, ATparity, color= \"green\")\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel('Genome Coordinates')\n",
    "# frequency label\n",
    "plt.ylabel('(A-T)/(A+T)')\n",
    "# plot title\n",
    "plt.title('S. aureus AT parity')\n",
    "# showing legend\n",
    "#plt.legend()\n",
    "\n",
    "# function to show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4: Locating the breakpoint(s)\n",
    "* Not a simple problem. In fact one (breakpoint detection) for which research is ongoing in many fields\n",
    "* Things you could try:\n",
    "    * Using derivation (checking the difference between each value and the previous one)\n",
    "    * Density-based approaches: Trying to locate the region around which changes in the sign occur more robustly (i.e. given many different points around it)\n",
    "\n",
    "#### Concept. Binary Searches   (revisit this!)\n",
    "* Let's think of a simpler problem first:\n",
    "Suppose you are given a quadratic equation: f(x)=ax**2+bx+c and you are asked to locate a root of the equation in an interval [k,m].\n",
    "* How would you proceed?\n",
    "* A fast and efficient way is to start by checking the values f(k) and f(m). If their product in f(k)f(m)<0 this means that the function \"crosses\" the x-axis at some point between k and m. (This stems from Lagrange's mean value theorem). The question is how then can we locate that point?\n",
    "* What we have in our hands is quite similar. We know that AT (or GC) parity values are expected to change their sign at two points in the genome (coinciding with the origin and terminus of replication). We need a way to locate this sign-transitions in a fast and accurate manner.\n",
    "\n",
    "#### Take a pause and think. \n",
    "1. How would you do it with an exhaustive (brute-force) approach?\n",
    "2. How would you try to do it with a divide-and-conquer approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, we show a function that takes as input the genomefile, a window of parity calculation, the type of parity (AT or GC) and one additional parameter, which we call \"threshold\" and which we will use to assess the proximity to a transition point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A brute-force with a threshold\n",
    "\n",
    "def bruteParity(genomefile, window, type, threshold):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import regex as re  \n",
    "\n",
    "    f = open(genomefile, 'r')\n",
    "    seq = \"\"\n",
    "    total = 0\n",
    "    A=T=G=C=[]\n",
    "    times=0;\n",
    "    for line in f:\n",
    "        x=re.match(\">\", line)\n",
    "        if x == None:\n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "    f.close()\n",
    "\n",
    "    x = []\n",
    "    parity = []\n",
    "    transitions = []\n",
    "    step = int(window/10)\n",
    "    times = int(len(seq)/step);\n",
    "    for i in range(times):\n",
    "        x.append(i*step)\n",
    "        DNA=seq[i*step:i*step+window]\n",
    "        A=DNA.count(\"A\")\n",
    "        T=DNA.count(\"T\")\n",
    "        C=DNA.count(\"C\")\n",
    "        G=DNA.count(\"G\")\n",
    "        if type == \"AT\":\n",
    "            parity.append(float(A-T)/float(A+T))\n",
    "            if (abs(float(A-T)/float(A+T)) < threshold):\n",
    "                transitions.append(i*step)\n",
    "        if type == \"GC\":\n",
    "            parity.append(float(G-C)/float(G+C))\n",
    "            if (abs(float(G-C)/float(G+C)) < threshold):\n",
    "                transitions.append(i*step)\n",
    "    \n",
    "    # Plot Parity and Predicted Transitions\n",
    "    plt.plot(x, parity, color= \"green\", linewidth = 3.0)\n",
    "    plt.axhline(y = 0, color = 'grey', linewidth = 2.0)\n",
    "\n",
    "    # plotting vertical lines at Ori and Ter\n",
    "    for site in transitions:\n",
    "        plt.axvline(x = site, color = 'black')\n",
    "\n",
    "    #plt.scatter(x, parity, color= \"green\")\n",
    "\n",
    "    # x-axis label\n",
    "    plt.xlabel('Genome Coordinates')\n",
    "    # frequency label\n",
    "    plt.ylabel('Relative Difference')\n",
    "    # plot title\n",
    "    plt.title('Parity')\n",
    "    # showing legend\n",
    "    #plt.legend()\n",
    "\n",
    "    # function to show the plot\n",
    "    plt.show()\n",
    "\n",
    "    return(transitions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we do in this case is very simple:\n",
    "1. We go on by calculating the parity in a given window\n",
    "2. We set an absolute value threshold below which we consider the parity to be zero\n",
    "3. We ask the script to report the positions were this is true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteParity('files/Staaur.fa', 100000, 'AT', 0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we locate the two main transition points plus an extra one. We actually have to tune the resolution parameter a bit to get the correct positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteParity('files/Staaur.fa', 100000, 'AT', 0.005)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the genome and its shape of the parity profile we need to tune the parameters accordingly and, obviously, this is not a good strategy for unknown genomes. Let's see for instance how the same parameteres behave in the case of E. coli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteParity('files/ecoli.fa', 100000, 'AT', 0.005)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AT is not a good choice for E. coli, so we switch to GC parity, for which, relaxing the threshold a bit (at 0.01) allows us to define the major transition point. In this case, the other point coincides with the beginning and end of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteParity('files/ecoli.fa', 100000, 'GC', 0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is, now, if this could be improved in a way that would not require tuning of parameters except from the choice of parity profile (AT or GC). \n",
    "\n",
    "#### A Divide and Conquer approach (think about it)\n",
    "We can think of a way that proceeds iteratively by narrowing down the space where the transition is being searched for. One such approach would be to roughly estimate the location of the transition in a range and then proceed by splitting that range in smaller and smaller pieces. This could work in the case of a single transition as is the one of E. coli."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercises\n",
    "1. Use a genomic signature approach to locate possible HGT genes in the genome of _St. aureus_. Do your results of \"outliers\" differ from those obtained with the GC content approach?\n",
    "2. Employ a similar approach for HGT detection but using Genomic Signatures for k=2 or k=3.\n",
    "3. Write a faster program to locate the origin of replication for a given bacterial genome using the parity rules described in the lecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extras (KEDIVIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hgWGC = windowGC(\"files/hg19_chr1_part.fa\", 10000)\n",
    "# Create a figure and axis\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the line\n",
    "plt.plot(hgWGC.keys(), hgWGC.values(), label='H. sapiens, chr1', color='blue', linewidth=2)  \n",
    "\n",
    "# Add labels and title\n",
    "plt.title('GC content along the genome')\n",
    "plt.xlabel('genome coordinates')\n",
    "plt.ylabel('GC%')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "allkmers('files/hg19_chr1_part.fa', 2)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg2mers = rkmers('files/hg19_chr1_part.fa', 2)\n",
    "type(hg2mers)\n",
    "print(hg2mers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hgk = rkmers('files/hg19_chr1_part.fa', 2)\n",
    "hg2mers = dict(sorted(hg2mers.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Extract keys and values from the dictionary\n",
    "items = list(hg2mers.keys())\n",
    "values = list(hg2mers.values())\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(items, values, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('k-mers')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequencies of Occurrence (k=2, Homo sapiens)')\n",
    "\n",
    "# Show grid for better readability\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfasta(fastafile):\n",
    "    import regex as re\n",
    "    f=open(fastafile, 'r')\n",
    "    seq = \"\"\n",
    "    total = 0\n",
    "    for line in f:\n",
    "        x=re.match(\">\", line)\n",
    "        if x == None:\n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "    seq=seq.replace('N','')\n",
    "    f.close()\n",
    "    return(seq)\n",
    "\n",
    "def CpGfinder(seq):\n",
    "    C=seq.count(\"C\")/len(seq)\n",
    "    G=seq.count(\"G\")/len(seq)\n",
    "    CpG=seq.count(\"CG\")\n",
    "\n",
    "    GCcont=float(G+C)\n",
    "    CpGobs=float(CpG/(len(seq)-1))\n",
    "    rCpG = float(CpGobs/(C*G))\n",
    "\n",
    "    return(GCcont, rCpG)\n",
    "\n",
    "def scanSeq(seq, window, step):\n",
    "    times=int(len(seq)/step)\n",
    "    x = []\n",
    "    for i in range(times):\n",
    "        x.append(i*step)\n",
    "        DNA=seq[i*step:i*step+window]\n",
    "        results=CpGfinder(DNA)\n",
    "        if((results[0]>=0.5) & (results[1]>=0.6)):\n",
    "            print(i*step,\"-\",i*step+200, results)\n",
    "\n",
    "scanSeq(readfasta(\"files/hg19_chr1_part.fa\"), 10000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def needleman_wunsch(seq1, seq2, match_score=1, mismatch_penalty=0, gap_penalty=-2):\n",
    "    # Initialize the scoring matrix\n",
    "    n = len(seq1)\n",
    "    m = len(seq2)\n",
    "    \n",
    "    # Create a (n+1) x (m+1) matrix\n",
    "    score_matrix = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "    \n",
    "    # Initialize the first row and column of the matrix\n",
    "    for i in range(n + 1):\n",
    "        score_matrix[i][0] = i * gap_penalty\n",
    "    for j in range(m + 1):\n",
    "        score_matrix[0][j] = j * gap_penalty\n",
    "\n",
    "    # Fill the scoring matrix\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            match = score_matrix[i - 1][j - 1] + (match_score if seq1[i - 1] == seq2[j - 1] else mismatch_penalty)\n",
    "            delete = score_matrix[i - 1][j] + gap_penalty\n",
    "            insert = score_matrix[i][j - 1] + gap_penalty\n",
    "            score_matrix[i][j] = max(match, delete, insert)\n",
    "\n",
    "    # Trace back to find the optimal alignment\n",
    "    aligned_seq1 = []\n",
    "    aligned_seq2 = []\n",
    "    \n",
    "    i, j = n, m\n",
    "    while i > 0 or j > 0:\n",
    "        current_score = score_matrix[i][j]\n",
    "        \n",
    "        if i > 0 and j > 0:\n",
    "            if current_score == score_matrix[i - 1][j - 1] + (match_score if seq1[i - 1] == seq2[j - 1] else mismatch_penalty):\n",
    "                aligned_seq1.append(seq1[i - 1])\n",
    "                aligned_seq2.append(seq2[j - 1])\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "                continue\n",
    "        \n",
    "        if i > 0 and current_score == score_matrix[i - 1][j] + gap_penalty:\n",
    "            aligned_seq1.append(seq1[i - 1])\n",
    "            aligned_seq2.append('-')\n",
    "            i -= 1\n",
    "        else:\n",
    "            aligned_seq1.append('-')\n",
    "            aligned_seq2.append(seq2[j - 1])\n",
    "            j -= 1\n",
    "\n",
    "    # Reverse the aligned sequences since we traced back\n",
    "    aligned_seq1.reverse()\n",
    "    aligned_seq2.reverse()\n",
    "\n",
    "    return ''.join(aligned_seq1), ''.join(aligned_seq2), score_matrix[n][m]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    sequence_1 = \"ATTCCGCCCAATTACGGA\"\n",
    "    sequence_2 = \"ATCGCCCAAACGGA\"\n",
    "\n",
    "    alignment_1, alignment_2, final_score = needleman_wunsch(sequence_1, sequence_2)\n",
    "    \n",
    "    print(\"Alignment:\")\n",
    "    print(alignment_1)\n",
    "    print(alignment_2)\n",
    "    print(\"Final Score:\", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burrows_wheeler_transform(input_string):\n",
    "    # Append a unique end character to the input string\n",
    "    input_string += '$'\n",
    "    \n",
    "    # Generate all cyclic rotations of the input string\n",
    "    rotations = [input_string[i:] + input_string[:i] for i in range(len(input_string))]\n",
    "    \n",
    "    # Sort the rotations lexicographically\n",
    "    sorted_rotations = sorted(rotations)\n",
    "    \n",
    "    # Extract the last column from the sorted rotations\n",
    "    last_column = ''.join(rotation[-1] for rotation in sorted_rotations)\n",
    "    \n",
    "    # Find the index of the original string in the sorted rotations\n",
    "    original_index = sorted_rotations.index(input_string)\n",
    "    \n",
    "    return last_column, original_index\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"ATGCACACTTTACACATGGG\"\n",
    "    bwt_result, index = burrows_wheeler_transform(input_text)\n",
    "    \n",
    "    print(\"Input text: \", input_text)\n",
    "    print(\"Burrows-Wheeler Transform: \", bwt_result)\n",
    "    print(\"Index of original string in sorted rotations: \", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burrows_wheeler_decode(last_column, original_index):\n",
    "    # Step 1: Create a table to hold the sorted characters\n",
    "    n = len(last_column)\n",
    "    \n",
    "    # Create a list of tuples (character, original index)\n",
    "    table = [(last_column[i], i) for i in range(n)]\n",
    "    \n",
    "    # Step 2: Sort the table by the first element (the character)\n",
    "    table.sort()\n",
    "\n",
    "    # Step 3: Create an array to hold the first column\n",
    "    first_column = [table[i][0] for i in range(n)]\n",
    "\n",
    "    # Step 4: Create an array to track the next indices\n",
    "    next_indices = [0] * n\n",
    "    for i in range(n):\n",
    "        next_indices[i] = table.index((last_column[i], i))\n",
    "\n",
    "    # Step 5: Reconstruct the original string\n",
    "    decoded_string = []\n",
    "    index = original_index\n",
    "    \n",
    "    for _ in range(n):\n",
    "        decoded_string.append(last_column[index])\n",
    "        index = next_indices[index]\n",
    "\n",
    "    return ''.join(decoded_string[::-1])  # Reverse to get the original string\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    last_column = \"GTCCC$CGAAAAGTGTTAAT\"  # Example last column from BWT\n",
    "    original_index = 3        # Example index of original string in sorted rotations\n",
    "\n",
    "    decoded_text = burrows_wheeler_decode(last_column, original_index)\n",
    "    \n",
    "    print(\"Decoded Text:\", decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
