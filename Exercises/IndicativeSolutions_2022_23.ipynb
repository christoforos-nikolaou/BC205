{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Class (May 2023)\n",
    "### Exercises - Indicative Solutions - Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some auxiliary functions\n",
    "\n",
    "# Reading a fast file\n",
    "def readfasta(fastafile):\n",
    "    import regex as re\n",
    "    f=open(fastafile, 'r')\n",
    "    seq = \"\"\n",
    "    total = 0\n",
    "    for line in f:\n",
    "        x=re.match(\">\", line)\n",
    "        if x == None:\n",
    "            length=len(line)\n",
    "            total=total+length\n",
    "            seq=seq+line[0:length-1]\n",
    "    f.close()\n",
    "    seq=seq.replace('N','')\n",
    "    return(seq)\n",
    "\n",
    "# A maximum function\n",
    "def maximum(x, y) :\n",
    "    if x > y :\n",
    "        return x\n",
    "    else :\n",
    "        return y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Palindromes. Finding them, extracting the greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 1: Iteration \n",
    "\n",
    "def longestpalindrome(s):\n",
    "  palindromes=[]\n",
    "  for i in range(1,len(s)):\n",
    "    try:\n",
    "        m=1 \n",
    "        while s[i-m]==s[i+m]:\n",
    "            palindromes.append(s[i-m:i+m+1])\n",
    "            m+=1\n",
    "    except:\n",
    "        pass\n",
    "  #return max(palindromes, key=len)\n",
    "  return sorted(palindromes, key=len, reverse=True)\n",
    "\n",
    "# Run\n",
    "ecoliseq=readfasta(\"../files/ecoli.fa\")\n",
    "longestpalindrome(ecoliseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 2: Recursion\n",
    "\n",
    "# we will build on a simple recursive function like the one given below\n",
    "\n",
    "def palindrome(mystring):\n",
    "    if len(mystring) < 2:\n",
    "        return True\n",
    "    if mystring[0] != mystring[-1]:\n",
    "        return False\n",
    "    return palindrome(mystring[1:-1])\n",
    "\n",
    "\n",
    "# We will next scan the sequence of the genome and call the function \n",
    "\n",
    "def recursivePalindrome(s):\n",
    "    palindromes = []\n",
    "    for i in range(0,len(s)):\n",
    "        k = 0\n",
    "        subsequence = s[i]\n",
    "        while (palindrome(subsequence)):\n",
    "            palindromes.append(subsequence)\n",
    "            k += 1\n",
    "            subsequence = s[i-k:i+k]\n",
    "        else:\n",
    "            next            \n",
    "            \n",
    "    #return max(palindromes, key=len)\n",
    "    return sorted(palindromes, key=len, reverse=True)\n",
    "\n",
    "ecoliseq=readfasta(\"../files/ecoli.fa\")\n",
    "recursivePalindrome(ecoliseq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "The solutions above do not yield the same palindrome. \n",
    "1. What is the problem with them?\n",
    "2. Which one is correct?\n",
    "3. Why is the one finding an odd-sized and the other an even-size palindrome?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow Algorithm\n",
    "In the above examples we implement a slower algorithm that is $O(nxm)$ where $n$ is the length of the longest sequence and $m$ is a factor that is related to the mean length of palindromes and their density inside the sequence (some sequences will take longer than others). \n",
    "\n",
    "### Odd/Even-Sized strings\n",
    "Both approaches shown above (iterative/recursive) fail to report both odd/even-sized palindromes because of the nature of their implementation. A simple and elegant solution to this problem is to modify the input string by adding the same (neutral) character in-between every residue/initial character. This will make all strings appear as odd-sized. E.g. if the string 'GCATTATT' is converted to '#G#C#A#T#T#A#T#T#' will be an odd-lengthed '#A#T#T#A#'. Below the final solution for the iterative version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longestpalindrome(s):\n",
    "    s=s.replace('','#')[1:-1]\n",
    "    palindromes=[]\n",
    "    for i in range(1,len(s)):\n",
    "        try:\n",
    "            m=1 \n",
    "            while s[i-m]==s[i+m]:\n",
    "                palindromes.append(s[i-m:i+m+1].replace('#',''))\n",
    "                m+=1\n",
    "        except:\n",
    "            pass\n",
    "    return sorted(palindromes, key=len, reverse=True)\n",
    "\n",
    "longestpalindrome(ecoliseq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Palindrome in linear time\n",
    "Finding the longest palindrome is a problem that has been shown to be solved in $O(n)$ time by Manacher and later additions.   \n",
    "  \n",
    "Manacher uses a simple but intuitive technique to speed up the process by taking the context of the string into consideration. For example in the string 'abracarba', by the time the process reaches the central 'c', the algorithm knows that the four final strings 'arba' form part of a palindrome. It can then treat them differently by going to the end of the string and from there examine what happens *downstream* of the already identified palindrome. This concept of \"context\" is explored in many other problems of \n",
    "  \n",
    "For those interested in this solution, you can find more [here](https://www.geeksforgeeks.org/manachers-algorithm-linear-time-longest-palindromic-substring-part-1/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Non-mers in E.coli Genome\n",
    "\n",
    "This was rather straight-forward as we had discussed it in class. Nevertheless, there is room for some discussion on optimization and the *assessment of statistical expectations*.   \n",
    "\n",
    "Below I provide code taken from one of your assignments, slightly modified and with comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../files/ecoli.fa\") as l:\n",
    "    l.readline()\n",
    "    ecolseq =\"\"\n",
    "    for ln in l:\n",
    "        lnseq = ln.strip()\n",
    "        ecolseq += lnseq\n",
    "\n",
    "#Find all the possible 10-mers that can be found with the 4 nucleotides\n",
    "import itertools\n",
    "\n",
    "k=10\n",
    "bases = [\"A\",\"T\",\"G\",\"C\"]\n",
    "combos = itertools.product(bases, repeat=k)\n",
    "strcomb = (\"\".join(y) for y in combos) #generators save memory compared to lists\n",
    "\n",
    "#Find all k-mers/10-mers in the genome\n",
    "\n",
    "kmers=[]\n",
    "for i in range(len(ecolseq)-k+1):\n",
    "    kmers.append(ecolseq[i:i+k])\n",
    "\n",
    "#Isolation of all the unique ones (makes the procedure faster)\n",
    "kmers = set(kmers)\n",
    "\n",
    "#Calculating how many 10-mers are not included in the E.coli genome\n",
    "count=0\n",
    "nonkmers =[]\n",
    "allk =0\n",
    "res =0\n",
    "for y in strcomb:\n",
    "    allk += 1     #control to check if the theoritical 4^10 has been produced with the product functional tool \n",
    "    if y not in kmers:\n",
    "        count +=1 #counting the 10-mers not included is same as len(nonkemers)/not necessary / check point\n",
    "        nonkmers.append(y)\n",
    "    else:         #not necessary / check point\n",
    "        res+=1    #counting the included 10-mers / check point\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "print(\"The number of non 10-mers is:\",count)\n",
    "print(\"Some of those non-mers are\", random.sample(nonkmers,10))\n",
    "\n",
    "# POINT: We can do the same without looping, simply by comparing sets\n",
    "allkmers = set([''.join(p) for p in itertools.product(bases, repeat=k)])\n",
    "nonmers = allkmers.difference(kmers)\n",
    "print(\"Found:\", len(nonmers), \"nonmers in the genome of E.coli\")\n",
    "\n",
    "#Expected non-10-mers/ Theoritical check: \n",
    "theor = 4**10\n",
    "obs = len(kmers)\n",
    "exp = theor - obs\n",
    "print(\"According to theory we would expect\", exp,\"non-mers since all the 10-mers are\", theor,\"and the observed in E.Coli are\", obs)\n",
    "\n",
    "# NOTE: The theoritical check is not in agreement with the ones found above with comparison. Not quite sure why.\n",
    "\n",
    "# =================================================================================================================\n",
    "# POINT: This is not correct from a theoretical viewpoint. In fact it is much more complex. Can you think of why?\n",
    "# =================================================================================================================\n",
    "\n",
    "\n",
    "#Another way to avoid for-loops and exhausting search is to immediately produce sets that contain unique 10-mers and calculate their difference:\n",
    "#The reading of the file is common\n",
    "\n",
    "# -> This is the point made above! (OK)\n",
    "\n",
    "kmers2 = {ecolseq[i:i+k] for i in range(len(ecolseq)-k+1) }\n",
    "combos = itertools.product(bases, repeat=k) \n",
    "#must to re-write the command since it's a generator that has been used above and needs to be generated to reused\n",
    "strcomb2 = {\"\".join(y) for y in combos} #permuation with replacement we can make it a set as they all uniq\n",
    "nonmers = strcomb2 - kmers2\n",
    "\n",
    "print(len(nonmers))\n",
    "print(random.sample(nonmers, 10)) #demonstartion of some non-mers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Did anyone try to use the binary search? Would it be faster?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. HGT and Clustering using odds Ratios\n",
    "\n",
    "Again, the technical aspects of these were discussed in class. It really is a matter of careful and detailed implementation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gibbs Sampler\n",
    "\n",
    "Due to lack of time I couldn't go through the details of all your code. Most of you were able to implement the Sampler but many could not make it converge to the actual result.  \n",
    "\n",
    "Below I am attaching an indicative solution. We can return to it, to see what may go wrong and at which point in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibbs Sampling to locate a motif in a set of sequences\n",
    "# code\n",
    "sequences = []\n",
    "with open ('../files/motifs_in_sequence.fa') as file:\n",
    "    for line in file:\n",
    "        sequences.append(line.strip()) # 50 sequences as elements of a list. 100 bases each sequence\n",
    "    \n",
    "\n",
    "##Gibbs sampler##\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def Gibbs_sampler(sequences,k): #k is the length of the motif, sequence is a list with the sequences\n",
    "    \n",
    "    dictionary = {'A':0,\n",
    "                  'T':1,\n",
    "                  'C':2,\n",
    "                  'G':3}\n",
    "    \n",
    "    column_sum = len(sequences) #number of rows (50) or number of sequences\n",
    "    length = len(sequences[0]) #number of columns or number of nucleotides in seq\n",
    "    Imax = 1.8*k #threshold of I\n",
    "    \n",
    "    pwm = np.zeros([4,k]) # A,T,C,G X len(motif)\n",
    "    \n",
    "    for seq in sequences:\n",
    "        rand_start = random.randint(0, length-k) #pick a random nucleotide from each sequence\n",
    "        motif = seq[rand_start:rand_start+k] #and take substring as the motif\n",
    "       \n",
    "        lst = enumerate(motif) #finding the index of each nucleotide in the motif to access the correct column\n",
    "                               #and using the dictionary to access the correct row \n",
    "        for i in lst: #making the first random pwm\n",
    "            pwm[dictionary[i[1]],i[0]]+=1\n",
    "            \n",
    "    pwm = pwm/column_sum\n",
    "    \n",
    "    information = np.zeros([1,k])\n",
    "    count=0\n",
    "    while (np.sum(information)) < Imax: #while information_content of the pwm \n",
    "        motives=[]                      #is less than the threshold\n",
    "        \n",
    "        information_old = np.sum(information) #keeping the previous value of information contect\n",
    "                                             #to check convergence in case the theshold \n",
    "        for row in range (column_sum):                #is never reached\n",
    "            maxx=0\n",
    "            rand_seq = random.randint(0, column_sum-1) #pick a random index - sequence\n",
    "            seq = sequences[rand_seq]               \n",
    "            for i in range(len(seq)-k):   #take each k-mer from the sequence \n",
    "                score = 0\n",
    "                substring = seq[i:i+k]\n",
    "                lst = enumerate(substring)\n",
    "                \n",
    "                for j in lst:                         #scoring each k-mer based on the pwm\n",
    "                    score+=pwm[dictionary[j[1]],j[0]]   #keeping the motif with the highest score\n",
    "                                                         #from each sequence\n",
    "                if score > maxx:  \n",
    "                    maxx = score\n",
    "                    motif = substring\n",
    "                    \n",
    "            motives += [motif] #keep all the motifs with the highest score in the list motives\n",
    "        \n",
    "        pwm = np.zeros([4,k]) # A,T,C,G X len(motif) \n",
    "        \n",
    "        for elem in motives: \n",
    "            lst = enumerate(elem)\n",
    "            for i in lst:         #making the new pwm\n",
    "                pwm[dictionary[i[1]],i[0]]+=1\n",
    "                 \n",
    "        pwm = pwm/column_sum\n",
    "        \n",
    "        information = np.zeros([1,k]) #computing the information of each position\n",
    "        for i in range(k):\n",
    "            information[0,i] = 2-abs(sum([elem*np.log2(elem) for elem in pwm[:,i] if elem > 0]))\n",
    "            \n",
    "\n",
    "        if abs(information_old - np.sum(information)) <= 0.5: #ckecking convergence \n",
    "            count+=1\n",
    "            if count == 10: #if the difference of the information content is less or equal to 0.5\n",
    "                break       #for consecutive 10 iterations then break\n",
    "        else:\n",
    "            count=0\n",
    "    \n",
    "    max_index_col = np.argmax(pwm, axis=0) #extracting the motif according to the   \n",
    "                                           #highest frequency of each nucleotide in each position\n",
    "    motif=''\n",
    "    for values in max_index_col:\n",
    "        for keys in dictionary.keys():\n",
    "            if values == dictionary[keys]:\n",
    "                motif+= keys\n",
    "        \n",
    "    return pwm,information,motif\n",
    "\n",
    "\n",
    "#repeat the algorithmm 100 times for each k (3 to 7) and keep the pwm and motif with the highest infromation_content\n",
    "#this process takes approximately 4min (in my computer)\n",
    "    \n",
    "####100-cycled GIbbs#####\n",
    "for k in range (3,8):\n",
    "    highest_info = 0\n",
    "    for i in range (100):\n",
    "        summ=0\n",
    "        pwm, information_content,motif = Gibbs_sampler(sequences,k)\n",
    "        summ+=np.sum(information_content)\n",
    "        if summ > highest_info:\n",
    "            highest_info = summ\n",
    "            pwm_ret = pwm\n",
    "            motif_ret = motif\n",
    "        \n",
    "    print('\\nThe information content of the motif divided by it\\'s length is:',highest_info/k) #divide by length to normalize and compare among other k\n",
    "    print('The pwm of the motif is:\\n',pwm_ret)\n",
    "    print('The motif is:',motif_ret)\n",
    "\n",
    "\n",
    "\n",
    "#To find the motifs for each k with the highest information content i have to repeat gibbs sampler many times because of the randomness that takes place\n",
    "#The motif that returns the highest scaled information content is GAT (k = 3, I/k = 1.9528 or 2!) but i think that the motif that we are looking for\n",
    "#is the motif GATA (k=4, I/k = 1.857) which contains GAT and is contained in all the longer found motifs.\n",
    "#(Also we know the existence of the GATA transcription factors and indeed GATA is part of these binding sites)\n",
    "#Sometimes the algorithm returns other 3-mers (eg ATG,GGC,AAG) with high information content as well but it\n",
    "#is noted that GATA is returned almost in every repetition of the 100-cycled Gibbs which means that it may be the only 4-mer motif with so high information content.\n",
    "#Finally i have to report that the threshold that i chose for checking convergence may not be the best choice and should be stricter\n",
    "#Either way i kept this threshold because otherwise i would have made the algorithm a lot slower (is already slow though :P)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Common Subsequence between two sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Longest Common Contiguous Subsequence is: GTA\n"
     ]
    }
   ],
   "source": [
    "### Longest Common Subsequence\n",
    "def longest_common_contiguous_subsequence(seq1, seq2):\n",
    "    m, n = len(seq1), len(seq2)\n",
    "    \n",
    "    # Create a 2D array to store lengths of longest common contiguous subsequence\n",
    "    # Initialize all values to 0\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Variable to keep track of the length of the longest common contiguous subsequence\n",
    "    max_length = 0\n",
    "    # Variable to store the ending index of the longest common contiguous subsequence in seq1\n",
    "    end_index_seq1 = 0\n",
    "\n",
    "    # Build the dp array from bottom up\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if seq1[i - 1] == seq2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                if dp[i][j] > max_length:\n",
    "                    max_length = dp[i][j]\n",
    "                    end_index_seq1 = i\n",
    "            else:\n",
    "                dp[i][j] = 0\n",
    "\n",
    "    # The longest common contiguous subsequence\n",
    "    longest_common_substr = seq1[end_index_seq1 - max_length:end_index_seq1]\n",
    "    \n",
    "    return longest_common_substr\n",
    "\n",
    "# Example usage\n",
    "seq1 = \"AGGTAB\"\n",
    "seq2 = \"XXAGTAYBYBYB\"\n",
    "print(f\"The Longest Common Contiguous Subsequence is: {longest_common_contiguous_subsequence(seq1, seq2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Suffix Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix Array: [21, 7, 9, 14, 17, 5, 0, 11, 22, 8, 16, 10, 15, 2, 18, 3, 6, 1, 19, 12, 20, 13, 4]\n"
     ]
    }
   ],
   "source": [
    "def build_suffix_array(seq):\n",
    "    # Generate all suffixes of the given sequence along with their starting indices\n",
    "    suffixes = [(seq[i:], i) for i in range(len(seq))]\n",
    "    \n",
    "    # Sort the suffixes lexicographically\n",
    "    suffixes.sort()\n",
    "    \n",
    "    # Extract and return the starting indices of the sorted suffixes\n",
    "    suffix_array = [suffix[1] for suffix in suffixes]\n",
    "    \n",
    "    return suffix_array\n",
    "\n",
    "# Example usage\n",
    "seq = \"AGCCTAGACACAGTACCACGTAB\"\n",
    "suffix_array = build_suffix_array(seq)\n",
    "print(f\"Suffix Array: {suffix_array}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BWT and Compression with RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence: AGGTABAGGTAB$\n",
      "Suffix Array: [12, 10, 4, 6, 0, 11, 5, 7, 1, 8, 2, 9, 3]\n",
      "Reordered Sequence: $AAAABBGGGGTT\n",
      "Compressed Sequence: $1A4B2G4T2\n"
     ]
    }
   ],
   "source": [
    "def build_suffix_array(seq):\n",
    "    suffixes = [(seq[i:], i) for i in range(len(seq))]\n",
    "    suffixes.sort()\n",
    "    suffix_array = [suffix[1] for suffix in suffixes]\n",
    "    return suffix_array\n",
    "\n",
    "def reorder_sequence(seq, suffix_array):\n",
    "    reordered_seq = ''.join(seq[i] for i in suffix_array)\n",
    "    return reordered_seq\n",
    "\n",
    "def run_length_encoding(seq):\n",
    "    if not seq:\n",
    "        return \"\"\n",
    "    \n",
    "    encoding = []\n",
    "    prev_char = seq[0]\n",
    "    count = 1\n",
    "    \n",
    "    for char in seq[1:]:\n",
    "        if char == prev_char:\n",
    "            count += 1\n",
    "        else:\n",
    "            encoding.append(prev_char + str(count))\n",
    "            prev_char = char\n",
    "            count = 1\n",
    "    encoding.append(prev_char + str(count))\n",
    "    \n",
    "    return ''.join(encoding)\n",
    "\n",
    "# Example usage\n",
    "seq = \"AGGTABAGGTAB$\"\n",
    "suffix_array = build_suffix_array(seq)\n",
    "reordered_seq = reorder_sequence(seq, suffix_array)\n",
    "compressed_seq = run_length_encoding(reordered_seq)\n",
    "\n",
    "print(f\"Original Sequence: {seq}\")\n",
    "print(f\"Suffix Array: {suffix_array}\")\n",
    "print(f\"Reordered Sequence: {reordered_seq}\")\n",
    "print(f\"Compressed Sequence: {compressed_seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Palindrome of a Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Palindromic Substring (Expand Around Center): ABA\n"
     ]
    }
   ],
   "source": [
    "### Take 1. Simple Expansion Around Center\n",
    "def longest_palindromic_substring_expand_center(s):\n",
    "    n = len(s)\n",
    "    if n == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        len1 = expand_around_center(s, i, i)\n",
    "        len2 = expand_around_center(s, i, i + 1)\n",
    "        max_len = max(len1, len2)\n",
    "        \n",
    "        if max_len > end - start:\n",
    "            start = i - (max_len - 1) // 2\n",
    "            end = i + max_len // 2\n",
    "    \n",
    "    return s[start:end + 1]\n",
    "\n",
    "def expand_around_center(s, left, right):\n",
    "    while left >= 0 and right < len(s) and s[left] == s[right]:\n",
    "        left -= 1\n",
    "        right += 1\n",
    "    return right - left - 1\n",
    "\n",
    "# Example usage\n",
    "dna_sequence = \"AGGTABAGGTAB\"\n",
    "longest_palindrome = longest_palindromic_substring_expand_center(dna_sequence)\n",
    "print(f\"Longest Palindromic Substring (Expand Around Center): {longest_palindrome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Palindromic Substring (DP): GABAG\n"
     ]
    }
   ],
   "source": [
    "### Take 2. Using Dynamic Programming\n",
    "def longest_palindromic_substring_dp(s):\n",
    "    n = len(s)\n",
    "    if n == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Initialize a table to store palindrome status\n",
    "    dp = [[False] * n for _ in range(n)]\n",
    "    \n",
    "    start = 0\n",
    "    max_length = 1\n",
    "    \n",
    "    # All substrings of length 1 are palindromes\n",
    "    for i in range(n):\n",
    "        dp[i][i] = True\n",
    "    \n",
    "    # Check for substrings of length 2\n",
    "    for i in range(n - 1):\n",
    "        if s[i] == s[i + 1]:\n",
    "            dp[i][i + 1] = True\n",
    "            start = i\n",
    "            max_length = 2\n",
    "    \n",
    "    # Check for lengths greater than 2\n",
    "    for length in range(3, n + 1):\n",
    "        for i in range(n - length + 1):\n",
    "            j = i + length - 1\n",
    "            \n",
    "            if s[i] == s[j] and dp[i + 1][j - 1]:\n",
    "                dp[i][j] = True\n",
    "                start = i\n",
    "                max_length = length\n",
    "    \n",
    "    return s[start:start + max_length]\n",
    "\n",
    "# Example usage\n",
    "dna_sequence = \"AGGTGABAGGTAB\"\n",
    "longest_palindrome = longest_palindromic_substring_dp(dna_sequence)\n",
    "print(f\"Longest Palindromic Substring (DP): {longest_palindrome}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
