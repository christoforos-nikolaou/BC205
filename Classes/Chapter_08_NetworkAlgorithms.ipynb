{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC205: Algorithms for Bioinformatics.\n",
    "## VI. Rapid Searches\n",
    "\n",
    "### Christoforos Nikolaou\n",
    "\n",
    "### Introduction\n",
    "\n",
    "#### Sequence similarity. Up to now:\n",
    "\n",
    "Dealing with the problem of sequence similarity and comparison, we have up to now seen how:\n",
    "* We can quantify the similarity between two sequences using scoring schemes that are either arbitrarily defined, or based on **substitution matrices** obtained from molecular evolution approaches.\n",
    "* We can define an objective methodology that maximizes sequence similarity through the concept of **alignment**.\n",
    "* We can distinguish between **global** (for the entire sequence length) and **local** (for subparts of the sequences) alignment.\n",
    "\n",
    "#### More complex problems\n",
    "We are now moving on into a different aspect of the problem of sequence similarity that stems from the scale of sequence size and volume.  \n",
    "\n",
    "Consider the following problems:\n",
    "\n",
    "1. We need to check the similarity not between two sequences but between one sequence and a much longer one (such as, for instance, a whole genome).\n",
    "2. We would like to search for similarity for a given sequence in a database that contains hundreds of thousands, or millions of sequences.  \n",
    "  \n",
    "In both of the above problems we cannot proceed with sequence alignment in the way we have seen up to now. In fact we need to consider rather different strategies for rapid sequence matches. In this and the next week, we will discuss:\n",
    "\n",
    "a. How we may approach the problem of similarity with identical matches. These sound more restrictive than the alignment concept but we will see how we can apply alignment strategies on selected identical matching \"seeds\" that effectively help us speed up the whole process.\n",
    "\n",
    "b. How we can use data transformation techniques to enable the speeding up and paralelization of sequence searches.\n",
    "\n",
    "### Pattern Searches\n",
    "\n",
    "We will start from the simplest, yet fundamental approach in the string matching problem. Consider a long sequence we will call _sequence_, and a smaller one we will _pattern_. Our goal is to write a program that will identify matches of _pattern_ within _sequence_. Even though we are tempted to use pre-defined functions, it is a good exercise to try and think how we would do this from scratch.  \n",
    "\n",
    "### Naive Pattern Search\n",
    "\n",
    "Consider the simplest way possible. \n",
    "\n",
    "We start from the beginning of _sequence_ and scan substrings of length equal to pattern for one-to-one matches. We do this exhaustively for all substrings. Thus, the steps are:\n",
    "\n",
    "1. Start from sequence[0] and loop one residue at a time (i=0)    \n",
    "2. Take a substring from _sequence_ equal to _pattern_  \n",
    "3. Start from pattern[0] and compare to sequence[i] (j=0)\n",
    "4. If there is a mismatch, exit and go to 2, take next _i_\n",
    "5. If there are no mismatches and _j_ reaches the size of length of _pattern_, report a full match, go to 2 and take next _i_  \n",
    "  \n",
    "Below is a Python script to do this in the simplest way possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index  5\n",
      "Pattern found at index  25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Number of steps taken=', 26)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Pattern Searching algorithm\n",
    "def naivePatternSearch(pattern, sequence):\n",
    "    p = len(pattern)\n",
    "    s = len(sequence)\n",
    "    no = 0\n",
    " \n",
    "    # We slide pattern one residue/character at a time\n",
    "    for i in range(s - p + 1):\n",
    "        no += 1\n",
    "        j = 0\n",
    "        \n",
    "        # for each pairing of pattern to sequence we check characters starting from the beginning\n",
    "        while(j < p):\n",
    "            if (sequence[i + j] != pattern[j]): \n",
    "                break\n",
    "            j += 1\n",
    " \n",
    "        if (j == p):\n",
    "            print(\"Pattern found at index \", i)\n",
    "    return(\"Number of steps taken=\", no)\n",
    " \n",
    "naivePatternSearch('abba', 'IhateabbaandIdontlikealibabba')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Pattern Search. Limitations\n",
    "\n",
    "Can you spot problems with the approach above that make it slow and inefficient? In which algorithm category do you think it falls?\n",
    "\n",
    "### Optimized naive search\n",
    "\n",
    "There are actually two points that we should consider. One is that in a case of a long pattern that matches the fist _p-1_ positions but not in the final one, we may be doing a lot of comparisons we can do away with.\n",
    "The other is that we may be able to speed up the process provided that the _pattern_ has some particular properties, by sliding not 1 character at a time, but more. The condition is for the _pattern_ to be variable because when all characters of the _pattern_ are different, we can slide the pattern by more than 1. This is because when a mismatch occurs after _j_ matches, we know that the first character of pattern will not match the j matched characters because all characters of pattern are different. So we can always slide the pattern **not by 1 but by j** without missing any valid shifts. \n",
    "\n",
    "Following is the modified code that is optimized for the special patterns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index 5\n",
      "Pattern found at index 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Number of steps taken=', 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized Naive Search \n",
    "def optNaivePatternSearch(pattern, sequence):\n",
    "    p = len(pattern)\n",
    "    s = len(sequence)\n",
    "    i = 0\n",
    "    no = 0\n",
    "  \n",
    "    while i <= s-p:\n",
    "        no+=1\n",
    "        # For current index i, check for pattern match\n",
    "        for j in range(p):\n",
    "            if sequence[i+j] != pattern[j]:\n",
    "                break\n",
    "            j += 1\n",
    "  \n",
    "        if j==p:    # if pat[0...M-1] = txt[i,i+1,...i+M-1]\n",
    "            print(\"Pattern found at index \" + str(i))\n",
    "            i = i + p\n",
    "        elif j==0:\n",
    "            i = i + 1\n",
    "        else:\n",
    "            i = i+ j    # slide the pattern by j\n",
    "    return(\"Number of steps taken=\", no)\n",
    "\n",
    "optNaivePatternSearch('abba', 'IhateabbaandIdontlikealibabba')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the steps taken for the optimized approach are 3 fewer than the naive one. This is even stronger when the pattern is more variable than above. Compare:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Number of steps taken=', 27)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naivePatternSearch('ledzeppelin', 'IhateabbaledzeppeliniswhatIreallylove')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Number of steps taken=', 17)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optNaivePatternSearch('ledzeppelin', 'IhateabbaledzeppeliniswhatIreallylove')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that a pattern of large size makes the situation much faster since we don't need to slide it exhaustively. \n",
    "A number of exact pattern matching approaches are based on efficient pattern sliding techniques. In the following we will discuss some of the most common ones. \n",
    "\n",
    "### More efficient approaches in pattern sliding. The Knuth-Morris-Pratt Algorithm (KMP)\n",
    "\n",
    "Both naive approaches don’t work well in cases where we see many matching characters followed by a mismatching character. This is because we still have to try to match a large number of characters before realizing that an exact match is impossible. (Think, e.g. for the case of 'ledzeppelin' in 'Iloveledzeppelix'). \n",
    "\n",
    "The KMP matching algorithm focus **again** on the _pattern_ and in particular specific structural properties of the pattern. For instance if the pattern has recurring sub-patterns appearing more than once. The basic idea behind KMP’s algorithm is: whenever we detect a mismatch (after some matches), we already know some of the characters in the text of the next window. We take advantage of this information to avoid matching the characters that we know will anyway match.  \n",
    "  \n",
    "For instance check the following example:\n",
    "\n",
    "sequence : XXXXAAAAAXXBB\n",
    "pattern : AAA\n",
    "\n",
    "The _pattern_ will match three consecutive positions in sequence but because its structure is repetitive, once we have matched it for the first time, we don't need to match the first two positions in the second match. We can simply move to the third position and check that one to ascertain the match. \n",
    "\n",
    "#### Preprocessing in KMP\n",
    "KMP uses the structure of the pattern to allow for efficient slides like the one above. It does so by preprocessing the pattern. The idea of preprocessing is to create a **prefix array**, which is an array that will tell us how many positions we can \"jump\" every time we encounter a mismatch based on **what we have matched up to then**.\n",
    "\n",
    "The idea is the following:\n",
    "* Given a pattern _p_, then for every prefix _r_ of _p_:\n",
    "* Find the longest common prefix of _r_ that is also a suffix of _r_, named _rs_\n",
    "* Report the length of _rs_ \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Array Construction\n",
    "\n",
    "We will create an array, called the \"Longest Prefix-Suffix\" (LPS) array, to assist us in the search.\n",
    "\n",
    "Consider a prefix _r_ such as that _r=ACACA_\n",
    "1. All proper(=not containing itself) prefixes of _r_ are:  \n",
    "    A, AC, ACA and ACAC\n",
    "2. All proper suffixes of _r_ are: CACA, ACA, CA, A\n",
    "3. The longest substring that is both a prefix and a suffix of _r_ is ACA. It has a length=3.\n",
    "4. We assign 3 at the position where ACACA terminates in the prefix array.\n",
    "\n",
    "In this example _ACACA_ comes from a longer pattern that is _ACACACCAT_, the prefix array of which may be seen below:\n",
    "\n",
    "| A | C | A | C | A | C | C | A | T |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| 0 | 0 | 1 | 2 | 3 | 2 | 0 | 1 | 0 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see a function that performs the preprocessing on a given pattern and returns the prefix array: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 2, 3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmpPrefixArray(pattern):\n",
    "    kmp=[]\n",
    "    for i in range(len(pattern)+1):\n",
    "        subpattern=pattern[:i]\n",
    "        maxlen=0\n",
    "        for j in range(len(subpattern)):\n",
    "            if (subpattern[:j]==subpattern[-j:]) and (len(subpattern[j:])>maxlen):\n",
    "                maxlen=len(subpattern[:j])\n",
    "        kmp.append(maxlen)\n",
    "    kmp.pop(0)\n",
    "    return(kmp)\n",
    "\n",
    "kmpPrefixArray('ACACA')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the structure of the pattern changes the KMP Prefix Array. Repetitive patterns will contain non-zero values, while very variable/unstructed ones will lead to Prefix Arrays that will not be very helpful in facilitating \"jumps\".\n",
    "Compare:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmpPrefixArray('GAGCCGAGCCGAGTCTG')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmpPrefixArray('GATCGCGACGTTCAGCT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMP Search with the Prefix Array\n",
    "\n",
    "The next step now, is to use the Prefix Array to search the _sequence_. \n",
    "\n",
    "The idea is to use the LPS array to speed up the process by directing us at **which characters between string and pattern to match every time**.   \n",
    "\n",
    "\n",
    "The algorithm may be outligned as follows:  \n",
    "\n",
    "1. Start from the beginning _i_ of _sequence_ and _j_ of pattern.    \n",
    "2. For as long as there is a match continue matching.    \n",
    "3. Upon hitting a mismatch, check if _j=0_. If yes, move one character in _sequence_.  \n",
    "4. In _j_ is not equal to 0 (which means we are in the middle of the pattern), look at the value of _LPS[j-1]_.\n",
    "5. Consider j (the position in the pattern) to be equal to the value of _LPS[j-1]_ (e.g. if _LPS[j-1]==2_ then move to the third position of the pattern)   \n",
    "6. If _j_ reaches the length of the pattern, then a complete match has been reached. Return exact match. \n",
    "7. **After a match is found** move the pattern as many places as the **last** value of LPS indicates.  \n",
    "\n",
    "The key is this: In every case (either a match or a mismatch):   \n",
    "1. we take the **last matching residue** \n",
    "2. we look up its LPS value  \n",
    "3. we move the pattern **whose index matches that LPS value** and place it **at the position of the mismatch**  \n",
    "\n",
    "    \n",
    "Below you may see an implementation in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 25]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmpSearch(pattern, sequence):\n",
    "    successes=[]\n",
    "    kmppattern=kmpPrefixArray(pattern)\n",
    "    s=len(sequence)\n",
    "    p=len(pattern)\n",
    "    i=0 \n",
    "    j=0\n",
    "    while i < s:\n",
    "        if (sequence[i] == pattern[j]):\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else: \n",
    "            if j != 0:\n",
    "                j = kmppattern[j-1]\n",
    "            else:\n",
    "                i += 1\n",
    "        if j == p:\n",
    "            successes.append(i-j)\n",
    "            j = kmppattern[j-1]\n",
    "    return(successes)\n",
    "\n",
    "kmpSearch('abba', 'IhateabbaandIdontlikealibabba')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And [here](https://www.youtube.com/watch?v=pu2aO_3R118) you may find an explanatory video on how to build the LPS array and perform the slides in the KMP search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other approaches that use pattern preprocessing (not discussed in 2022-2023)\n",
    "\n",
    "A number of string matching algorithms that employ pattern preprocessing strategies exist. The most notable ones are:  \n",
    "1. The Boyer-Moore (BM) algorithm, uses a transformation of the pattern so that it instructs \"jumps\" in the case of mismatch (like the KMP algorithm).   \n",
    "2. Finite Automata (FA) transform the pattern in an object that is searchable with \"jumps\" between different states.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boyer Moore \n",
    "Below is an implementation of the Boyer Moore algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boyer Moore \n",
    " \n",
    " \n",
    "def badCharacterRule(string, size):\n",
    "    '''\n",
    "    The preprocessing function for\n",
    "    Boyer Moore's bad character heuristic\n",
    "    '''\n",
    " \n",
    "    # Initialize all occurrence as -1\n",
    "    badChar = [-1]*256\n",
    " \n",
    "    # Fill the actual value of last occurrence\n",
    "    for i in range(size):\n",
    "        badChar[ord(string[i])] = i;\n",
    " \n",
    "    # retun initialized list\n",
    "    return badChar\n",
    " \n",
    "def bmSearch(pattern, sequence):\n",
    "    '''\n",
    "    A pattern searching function that uses Bad Character\n",
    "    Heuristic of Boyer Moore Algorithm\n",
    "    '''\n",
    "    m = len(pattern)\n",
    "    n = len(sequence)\n",
    " \n",
    "    # create the bad character list by calling\n",
    "    # the preprocessing function badCharHeuristic()\n",
    "    # for given pattern\n",
    "    badChar = badCharacterRule(pattern, m)\n",
    " \n",
    "    # s is shift of the pattern with respect to text\n",
    "    s = 0\n",
    "    while(s <= n-m):\n",
    "        j = m-1\n",
    " \n",
    "        # Keep reducing index j of pattern while\n",
    "        # characters of pattern and text are matching\n",
    "        # at this shift s\n",
    "        while j>=0 and pattern[j] == sequence[s+j]:\n",
    "            j -= 1\n",
    " \n",
    "        # If the pattern is present at current shift,\n",
    "        # then index j will become -1 after the above loop\n",
    "        if j<0:\n",
    "            print(\"Pattern occur at shift = {}\".format(s))\n",
    " \n",
    "            '''   \n",
    "                Shift the pattern so that the next character in text\n",
    "                      aligns with the last occurrence of it in pattern.\n",
    "                The condition s+m < n is necessary for the case when\n",
    "                   pattern occurs at the end of text\n",
    "               '''\n",
    "            s += (m-badChar[ord(sequence[s+m])] if s+m<n else 1)\n",
    "        else:\n",
    "            '''\n",
    "               Shift the pattern so that the bad character in text\n",
    "               aligns with the last occurrence of it in pattern. The\n",
    "               max function is used to make sure that we get a positive\n",
    "               shift. We may get a negative shift if the last occurrence\n",
    "               of bad character in pattern is on the right side of the\n",
    "               current character.\n",
    "            '''\n",
    "            s += max(1, j-badChar[ord(sequence[s+j])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern occur at shift = 8\n",
      "Pattern occur at shift = 17\n"
     ]
    }
   ],
   "source": [
    "bmSearch('abra', 'avadaketabraandalabra')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αpproaches that employ transformation of the sequence \n",
    "\n",
    "1. Z-array transformation\\\n",
    "In the Z-array transformation the whole sequence (to be searched) and the pattern (query) are joined and separated by a single-time-occurring character (e.g. '$'), like so:\n",
    "\n",
    "pattern = 'abba'\n",
    "sequence = 'abraidontlikeabbailikethebeatles'\n",
    "\n",
    "So the whole string becomes\n",
    "string = 'abba$abraidontlikeabbailikethebeatles'\n",
    "\n",
    "The Z-array is then created in the following way. For each position in string, $string[i]$, $Z[i]$ is set as equal to the length of the longest substring starting from $[i]$ that is also a prefix of the whole string. In this way, any position in the Z-array with a score $Z[i]$ equal to the length of the  pattern, constitutes an identical match. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z algorithm for pattern searching\n",
    "  \n",
    "# Fills Z array for given string str[]\n",
    "def getZarr(string, z):\n",
    "    n = len(string)\n",
    "  \n",
    "    # [L,R] make a window which matches\n",
    "    # with prefix of s\n",
    "    l, r, k = 0, 0, 0\n",
    "    for i in range(1, n):\n",
    "  \n",
    "        # if i>R nothing matches so we will calculate.\n",
    "        # Z[i] using naive way.\n",
    "        if i > r:\n",
    "            l, r = i, i\n",
    "  \n",
    "            # R-L = 0 in starting, so it will start\n",
    "            # checking from 0'th index. For example,\n",
    "            # for \"ababab\" and i = 1, the value of R\n",
    "            # remains 0 and Z[i] becomes 0. For string\n",
    "            # \"aaaaaa\" and i = 1, Z[i] and R become 5\n",
    "            while r < n and string[r - l] == string[r]:\n",
    "                r += 1\n",
    "            z[i] = r - l\n",
    "            r -= 1\n",
    "        else:\n",
    "  \n",
    "            # k = i-L so k corresponds to number which\n",
    "            # matches in [L,R] interval.\n",
    "            k = i - l\n",
    "  \n",
    "            # if Z[k] is less than remaining interval\n",
    "            # then Z[i] will be equal to Z[k].\n",
    "            # For example, str = \"ababab\", i = 3, R = 5\n",
    "            # and L = 2\n",
    "            if z[k] < r - i + 1:\n",
    "                z[i] = z[k]\n",
    "  \n",
    "            # For example str = \"aaaaaa\" and i = 2, \n",
    "            # R is 5, L is 0\n",
    "            else:\n",
    "  \n",
    "                # else start from R and check manually\n",
    "                l = i\n",
    "                while r < n and string[r - l] == string[r]:\n",
    "                    r += 1\n",
    "                z[i] = r - l\n",
    "                r -= 1\n",
    "  \n",
    "# prints all occurrences of pattern \n",
    "# in text using Z algo\n",
    "def search(text, pattern):\n",
    "  \n",
    "    # Create concatenated string \"P$T\"\n",
    "    concat = pattern + \"$\" + text\n",
    "    l = len(concat)\n",
    "  \n",
    "    # Construct Z array\n",
    "    z = [0] * l\n",
    "    getZarr(concat, z)\n",
    "  \n",
    "    # now looping through Z array for matching condition\n",
    "    for i in range(l):\n",
    "  \n",
    "        # if Z[i] (matched region) is equal to pattern\n",
    "        # length we got the pattern\n",
    "        if z[i] == len(pattern):\n",
    "            print(\"Pattern found at index\", \n",
    "                      i - len(pattern) - 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rabin-Karp Algorithm\n",
    "\n",
    "The Rabin Karp Algorithm also acts on the whole sequence and the pattern. It uses a hashing strategy to assign a numerical value to every position in the sequence and the pattern. Then it only starts to match the pattern with positions in the sequence that start with the same hashing value. \n",
    "As numerical comparison is faster than string comparison the whole process is sped up. \n",
    "\n",
    "The problems comes with the hashing strategy. First the hashing function needs to be carefully defined so that is creates a broad range of values to avoid spurious hits. The other is that it needs to be a **rolling hash function**, meaning one that can update values on the go. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-4519cab7e033>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-4519cab7e033>\"\u001b[1;36m, line \u001b[1;32m43\u001b[0m\n\u001b[1;33m    print \"Pattern found at index \" + str(i)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Rabin Karp Algorithm with a Simple Rolling Hash\n",
    "  \n",
    "# d is the number of characters in the input alphabet\n",
    "d = 256\n",
    "  \n",
    "# pat  -> pattern\n",
    "# txt  -> text\n",
    "# q    -> A prime number\n",
    "  \n",
    "def search(pat, txt, q):\n",
    "    M = len(pat)\n",
    "    N = len(txt)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    p = 0    # hash value for pattern\n",
    "    t = 0    # hash value for txt\n",
    "    h = 1\n",
    "  \n",
    "    # The value of h would be \"pow(d, M-1)% q\"\n",
    "    for i in xrange(M-1):\n",
    "        h = (h * d)% q\n",
    "  \n",
    "    # Calculate the hash value of pattern and first window\n",
    "    # of text\n",
    "    for i in xrange(M):\n",
    "        p = (d * p + ord(pat[i]))% q\n",
    "        t = (d * t + ord(txt[i]))% q\n",
    "  \n",
    "    # Slide the pattern over text one by one\n",
    "    for i in xrange(N-M + 1):\n",
    "        # Check the hash values of current window of text and\n",
    "        # pattern if the hash values match then only check\n",
    "        # for characters on by one\n",
    "        if p == t:\n",
    "            # Check for characters one by one\n",
    "            for j in xrange(M):\n",
    "                if txt[i + j] != pat[j]:\n",
    "                    break\n",
    "  \n",
    "            j+= 1\n",
    "            # if p == t and pat[0...M-1] = txt[i, i + 1, ...i + M-1]\n",
    "            if j == M:\n",
    "                print \"Pattern found at index \" + str(i)\n",
    "  \n",
    "        # Calculate hash value for next window of text: Remove\n",
    "        # leading digit, add trailing digit\n",
    "        if i < N-M:\n",
    "            t = (d*(t-ord(txt[i])*h) + ord(txt[i + M]))% q\n",
    "  \n",
    "            # We might get negative values of t, converting it to\n",
    "            # positive\n",
    "            if t < 0:\n",
    "                t = t + q\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Into the world of biological sequences\n",
    "\n",
    "#### Problems that set the bar\n",
    "* Very large _corpora_, meaning a large number of sequences to be scanned in databases\n",
    "* Considerable numbers of query sequences, meaning the sequences we want to search for (it's not just one string)\n",
    "* Gaps should be allowed. We cannot expect identical matches to do all the work for us.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The FASTA Algorithm\n",
    "\n",
    "#### FastA - Steps  \n",
    "\n",
    "* Hashing: FastA locates regions of the query sequence and matching regions in the database sequences that have high densities of exact word matches. (without gaps) The length of the matched word is called the ktup parameter.  \n",
    "\n",
    "* Scoring: The ten highest scoring regions are rescored using a scoring matrix. The score for such a pair of regions is saved as the init1 score.\n",
    "\n",
    "* Introduction of Gaps: FastA determines if any of the initial regions from different diagonals may be joined together to form an approximate alignment with gaps. **Only non-overlapping regions may be joined**. The score for the joined regions is the sum of the scores of the initial regions minus a joining penalty for each gap. The score of the highest scoring region, at the end of this step, is saved as the initial score.  \n",
    "\n",
    "* Alignment: After computing the initial scores, FastA determines the best segment of similarity between the query sequence and the search set sequence, using a variation of the Smith-Waterman algorithm. The score for this alignment is the optimal score.  \n",
    "\n",
    "* Random Sequence Simulation: In order to evaluate the significance of such alignment FastA empirically estimates the score distribution from the alignment of many random pairs of sequences. More precisely, the characters of the query sequences are reshuffled (to maintain bias due to length and character composition) and searched against a random subset of the database. This empirical distribution is extrapolated, assuming it is an extreme value distribution, and each alignment to the real query is assigned a Z-score and an E-score.\n",
    "\n",
    "### A simplified version of the FASTA algorithm\n",
    "\n",
    "* Get two seqeunces (Q, S)\n",
    "* Choose a length k for kmers\n",
    "* Map all kmers in Q, S\n",
    "  \n",
    "![FASTA1](figures/FASTA2.JPG)\n",
    "\n",
    "* Create a matching matrix M. M is indexed for diagonals. The diagonals are indexed as i=m-n, where m is the position of each kmer in Q and n is the position of the corresponding kmer in S.\n",
    "\n",
    "![FASTA2](figures/FASTA1.JPG)\n",
    "\n",
    "\n",
    "* Every $S[i]$ is incremented with the corresponding kmer match\n",
    "\n",
    "![FASTAscoring](figures/FASTA4.JPG)\n",
    "\n",
    "* $S[i]$ with scores above a certain limit are kept to form part of the general alignment\n",
    "\n",
    "![FASTA3](figures/FASTA3.JPG)\n",
    "\n",
    "* The alignment is created with the stitching together of S[i] where _i_ are found within a given distance (range, or \"band\")\n",
    "\n",
    "![FASTA4](figures/BLASTStat.JPG)\n",
    "\n",
    "Below you may find a sample of the code to index the kmers for a given sequence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AA': [], 'AC': [0, 2, 4, 10, 12, 14, 19, 21], 'AG': [], 'AT': [], 'CA': [1, 3, 9, 11, 13, 20, 22], 'CC': [5], 'CG': [6, 15], 'CT': [], 'GA': [], 'GC': [], 'GG': [], 'GT': [7, 16], 'TA': [18], 'TC': [8], 'TG': [], 'TT': [17]}\n"
     ]
    }
   ],
   "source": [
    "# A function to index k-mers\n",
    "\n",
    "def indexKmers(sequence, k):\n",
    "    import itertools\n",
    "    import re\n",
    "    alphabet = ['A', 'C' , 'G', 'T']\n",
    "    kmers = [''.join(p) for p in list(itertools.product(alphabet, repeat=k))]\n",
    "    positions = {}\n",
    "    for kmer in kmers:\n",
    "        regex = '(?='+kmer+')'\n",
    "        positions[kmer] = [m.start() for m in re.finditer(regex, sequence)]\n",
    "    return(positions)\n",
    "\n",
    "kmersTEST = indexKmers('ACACACCGTCACACACGTTACACA', 2)\n",
    "print(kmersTEST)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLAST\n",
    "\n",
    "* BLAST is by far the most widely-used (and cited) Bioinformatics algorithm.  \n",
    "* It works by finding local alignments with mismatches and extends them by joining related (closely located) matched elements (HSP: high scoring segment pairs)  \n",
    "\n",
    "### The BLAST Algorithm \n",
    "BLAST is based on four parameters:  \n",
    "\n",
    "1. word length (w)  \n",
    "2. distance (d) of created dictionary (assumes a substitution table)  \n",
    "3. extension (e) for the distance within which HSP are joined \n",
    "4. E-value is the value on which the statistical inference of the final match is based  \n",
    "\n",
    "\n",
    "![BLAST](figures/BLAST.JPG)\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
